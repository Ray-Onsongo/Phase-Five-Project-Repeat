{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Market Intelligence System: Problem Statement\n",
    "\n",
    "## 1. Context & Problem\n",
    "\n",
    "The current job market is fragmented and opaque, creating significant inefficiencies for three key stakeholder groups:\n",
    "\n",
    "- **Job Seekers** face information overload, skill uncertainty, and lack of salary transparency.\n",
    "- **HR Professionals & Recruiters** struggle with competitive hiring, compensation benchmarking, and identifying skill gaps.\n",
    "- **Educational Institutions & Career Counselors** operate with outdated curriculum and lack real-time market data for guidance.\n",
    "\n",
    "**Core Problem:** There is no unified, data-driven system that transforms raw job posting data into actionable, real-time insights for all stakeholders.\n",
    "\n",
    "## 2. Project Goal\n",
    "\n",
    "To develop a **Job Market Intelligence System** that analyzes job posting data to generate clear, actionable insights on skill demand, geographic opportunity, salary benchmarks, and market trends.\n",
    "\n",
    "## 3. Key Objectives\n",
    "\n",
    "1.  **Skill Demand Analysis:** Identify trending and declining technical skills.\n",
    "2.  **Geographic Opportunity Mapping:** Visualize job distribution and hotspots.\n",
    "3.  **Salary Benchmarking:** Estimate compensation by role, experience, and location.\n",
    "4.  **Job Classification & Trend Identification:** Categorize postings and spot emerging roles.\n",
    "\n",
    "## 4. Primary Business Questions\n",
    "\n",
    "- **For Job Seekers:** \"What skills should I learn, where are the jobs, and what salary can I expect?\"\n",
    "- **For HR/Recruiters:** \"How competitive is the market, and are our offers aligned?\"\n",
    "- **For Educators:** \"Which skills and emerging roles should we teach for?\"\n",
    "\n",
    "## 5. Success Metrics\n",
    "\n",
    "- **Technical:** >80% classification accuracy; <$15k MAE for salary prediction.\n",
    "- **Business:** Delivery of actionable insights, clear visualizations, and identifiable market patterns to all stakeholder groups.\n",
    "\n",
    "## 6. Project Scope\n",
    "\n",
    "**In-Scope (Initial Focus):**\n",
    "- Analysis of provided job posting datasets.\n",
    "- Focus on English-language technical/professional roles.\n",
    "- Skills extraction and trend analysis from job descriptions.\n",
    "\n",
    "**Value Delivered:**\n",
    "- **Job Seekers:** Reduced search time, clearer career paths.\n",
    "- **HR Professionals:** Competitive intelligence, optimized recruitment.\n",
    "- **Educators:** Data-driven curriculum alignment and career guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now explore our dataset and understand its structure, quality and potential for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection\n",
    "We will now load the data andexamine its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD LIBRARIES\n",
    "import os                          # Interacting with the operating system (file paths, directories)\n",
    "import math                        # Math functions (e.g., sqrt)\n",
    "import pickle                      # Save/load Python objects\n",
    "import joblib                      # Save/load trained models efficiently\n",
    "\n",
    "# DATA MANIPULATION & NUMERICAL COMPUTATION\n",
    "import pandas as pd                # Data loading, cleaning, and manipulation\n",
    "import numpy as np                 # Numerical operations and array manipulation\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt    # General-purpose plotting\n",
    "import seaborn as sns              # Statistical data visualization\n",
    "\n",
    "# STATISTICS\n",
    "from scipy import stats             # Statistical functions, e.g., z-score, t-tests\n",
    "from scipy.stats import entropy     # Measure of information content (e.g., Shannon entropy)\n",
    "\n",
    "# MACHINE LEARNING\n",
    "import xgboost as xgb               # XGBoost for gradient boosting models\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,              # Split data into train/test sets\n",
    "    StratifiedKFold,               # Cross-validation preserving class distribution\n",
    "    GridSearchCV                   # Hyperparameter tuning\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,        # Random Forest classifier\n",
    "    VotingClassifier,              # Combine multiple models via voting\n",
    "    GradientBoostingRegressor      # Gradient boosting for regression\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression classifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    fbeta_score,                   # F-beta score for classification performance\n",
    "    precision_recall_curve,        # Precision-recall curve\n",
    "    classification_report,         # Detailed classification metrics\n",
    "    mean_squared_error,            # Regression metric\n",
    "    mean_absolute_error,           # Regression metric\n",
    "    auc,                           # Area under curve (ROC or PR)\n",
    "    confusion_matrix,              # True vs predicted labels summary\n",
    "    roc_curve,                     # Compute ROC curve for binary classification\n",
    "    make_scorer,                   # Create custom scoring function for model evaluation\n",
    "    precision_score,               # Precision metric\n",
    "    recall_score,                  # Recall metric\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler       # Feature scaling\n",
    "from sklearn.cluster import KMeans                     # Clustering algorithm\n",
    "from sklearn.decomposition import PCA                  # Principal Component Analysis (dimensionality reduction)\n",
    "from sklearn.inspection import permutation_importance  # Measure feature importance via performance drop\n",
    "from sklearn.calibration import CalibratedClassifierCV # Fixes overconfident probabilities\n",
    "\n",
    "# HANDLING IMBALANCED DATA\n",
    "from imblearn.over_sampling import SMOTE          # Synthetic oversampling for minority class\n",
    "from imblearn.pipeline import Pipeline            # Pipelines compatible with imbalanced-learn\n",
    "\n",
    "# MISCELLANEOUS SETTINGS\n",
    "pd.set_option(\"display.max_columns\", None)       # Display all columns in DataFrame\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                # Suppress warnings for cleaner output\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", font_scale=0.9)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)  # Default figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We got an error when trying to read in the dataset due to the unique encoding of the data inside the dataset. Therefore, we had to employ some encoding to debug the dataset and make it readable by the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe1 in position 46: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe1 in position 46: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a5535638dc62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mob_Posting_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Job_Posting_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mJob_Posting_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe1 in position 46: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "ob_Posting_df = pd.read_csv(\"Job_Posting_data.csv\")\n",
    "Job_Posting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying different encodings...\n",
      "SUCCESS with ISO-8859-1 encoding!\n",
      "   Shape: (9919, 21)\n",
      "   Columns: 21\n",
      "\n",
      "First 3 rows:\n",
      "  Website Domain  Ticker                                  Job Opening Title  \\\n",
      "0      bosch.com     NaN  IN_RBAI_Assistant Manager_Dispensing Process E...   \n",
      "1      bosch.com     NaN  Professional Internship: Hardware Development ...   \n",
      "2         zf.com     NaN                      Process Expert BMS Production   \n",
      "\n",
      "                                     Job Opening URL         First Seen At  \\\n",
      "0  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-29T19:59:45Z   \n",
      "1  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-04T01:00:12Z   \n",
      "2  https://jobs.zf.com/job/Shenyang-Process-Exper...  2024-04-19T06:47:24Z   \n",
      "\n",
      "           Last Seen At                 Location  \\\n",
      "0  2024-07-31T14:35:44Z   Indiana, United States   \n",
      "1  2024-07-29T17:46:16Z  Delaware, United States   \n",
      "2  2024-05-16T02:25:08Z                    China   \n",
      "\n",
      "                                       Location Data  \\\n",
      "0  [{\"city\":null,\"state\":\"Indiana\",\"zip_code\":nul...   \n",
      "1  [{\"city\":null,\"state\":\"Delaware\",\"zip_code\":nu...   \n",
      "2  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...   \n",
      "\n",
      "                           Category    Seniority Keywords  \\\n",
      "0  engineering, management, support      manager      NaN   \n",
      "1                        internship  non_manager    Scrum   \n",
      "2                       engineering  non_manager      SAP   \n",
      "\n",
      "                                         Description Salary  \\\n",
      "0  **IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...    NaN   \n",
      "1  **Professional Internship: Hardware Developmen...    NaN   \n",
      "2  ZF is a global technology company supplying sy...    NaN   \n",
      "\n",
      "                                         Salary Data  \\\n",
      "0  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
      "1  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
      "2  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
      "\n",
      "               Contract Types Job Status Job Language Job Last Processed At  \\\n",
      "0                   full time     closed           en  2024-08-02T14:47:55Z   \n",
      "1  full time, internship, m/f     closed           en  2024-07-31T17:50:07Z   \n",
      "2                         NaN     closed           en  2024-05-18T02:32:04Z   \n",
      "\n",
      "   O*NET Code                       O*NET Family  \\\n",
      "0  43-1011.00  Office and Administrative Support   \n",
      "1  17-2061.00       Architecture and Engineering   \n",
      "2  51-9141.00                         Production   \n",
      "\n",
      "                               O*NET Occupation Name  \n",
      "0  First-Line Supervisors of Office and Administr...  \n",
      "1                        Computer Hardware Engineers  \n",
      "2               Semiconductor Processing Technicians  \n",
      "\n",
      "Column names:\n",
      "   1. Website Domain\n",
      "   2. Ticker\n",
      "   3. Job Opening Title\n",
      "   4. Job Opening URL\n",
      "   5. First Seen At\n",
      "   6. Last Seen At\n",
      "   7. Location\n",
      "   8. Location Data\n",
      "   9. Category\n",
      "  10. Seniority\n",
      "  11. Keywords\n",
      "  12. Description\n",
      "  13. Salary\n",
      "  14. Salary Data\n",
      "  15. Contract Types\n",
      "  16. Job Status\n",
      "  17. Job Language\n",
      "  18. Job Last Processed At\n",
      "  19. O*NET Code\n",
      "  20. O*NET Family\n",
      "  21. O*NET Occupation Name\n"
     ]
    }
   ],
   "source": [
    "encodings_to_try = ['ISO-8859-1', 'cp1252', 'latin1', 'windows-1252', 'utf-8-sig', 'mac_roman']\n",
    "\n",
    "print(\"Trying different encodings...\")\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        Job_Posting_df = pd.read_csv(\"Job_Posting_data.csv\", encoding=encoding)\n",
    "        print(f\"SUCCESS with {encoding} encoding!\")\n",
    "        print(f\"   Shape: {Job_Posting_df.shape}\")\n",
    "        print(f\"   Columns: {len(Job_Posting_df.columns)}\")\n",
    "        print(f\"\\nFirst 3 rows:\")\n",
    "        print(Job_Posting_df.head(3))\n",
    "        print(\"\\nColumn names:\")\n",
    "        for i, col in enumerate(Job_Posting_df.columns, 1):\n",
    "            print(f\"  {i:2}. {col}\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Failed with {encoding}: {str(e)[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with {encoding}: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website Domain</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Job Opening Title</th>\n",
       "      <th>Job Opening URL</th>\n",
       "      <th>First Seen At</th>\n",
       "      <th>Last Seen At</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Data</th>\n",
       "      <th>Category</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Salary Data</th>\n",
       "      <th>Contract Types</th>\n",
       "      <th>Job Status</th>\n",
       "      <th>Job Language</th>\n",
       "      <th>Job Last Processed At</th>\n",
       "      <th>O*NET Code</th>\n",
       "      <th>O*NET Family</th>\n",
       "      <th>O*NET Occupation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN_RBAI_Assistant Manager_Dispensing Process E...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-05-29T19:59:45Z</td>\n",
       "      <td>2024-07-31T14:35:44Z</td>\n",
       "      <td>Indiana, United States</td>\n",
       "      <td>[{\"city\":null,\"state\":\"Indiana\",\"zip_code\":nul...</td>\n",
       "      <td>engineering, management, support</td>\n",
       "      <td>manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-02T14:47:55Z</td>\n",
       "      <td>43-1011.00</td>\n",
       "      <td>Office and Administrative Support</td>\n",
       "      <td>First-Line Supervisors of Office and Administr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional Internship: Hardware Development ...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-05-04T01:00:12Z</td>\n",
       "      <td>2024-07-29T17:46:16Z</td>\n",
       "      <td>Delaware, United States</td>\n",
       "      <td>[{\"city\":null,\"state\":\"Delaware\",\"zip_code\":nu...</td>\n",
       "      <td>internship</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>Scrum</td>\n",
       "      <td>**Professional Internship: Hardware Developmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time, internship, m/f</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-07-31T17:50:07Z</td>\n",
       "      <td>17-2061.00</td>\n",
       "      <td>Architecture and Engineering</td>\n",
       "      <td>Computer Hardware Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zf.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Process Expert BMS Production</td>\n",
       "      <td>https://jobs.zf.com/job/Shenyang-Process-Exper...</td>\n",
       "      <td>2024-04-19T06:47:24Z</td>\n",
       "      <td>2024-05-16T02:25:08Z</td>\n",
       "      <td>China</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>engineering</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>SAP</td>\n",
       "      <td>ZF is a global technology company supplying sy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-05-18T02:32:04Z</td>\n",
       "      <td>51-9141.00</td>\n",
       "      <td>Production</td>\n",
       "      <td>Semiconductor Processing Technicians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DevOps Developer with Python for ADAS Computin...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-08-16T10:20:37Z</td>\n",
       "      <td>2024-08-22T11:14:49Z</td>\n",
       "      <td>Romania</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>information_technology, software_development</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>GitHub, Jenkins, Growth, C++, Linux, Python, M...</td>\n",
       "      <td>**DevOps Developer with Python for ADAS Comput...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-23T00:33:30Z</td>\n",
       "      <td>15-1252.00</td>\n",
       "      <td>Computer and Mathematical</td>\n",
       "      <td>Software Developers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Engineer Sales - Video Systems and Solu...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-07-01T17:31:20Z</td>\n",
       "      <td>2024-08-01T05:11:33Z</td>\n",
       "      <td>India</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>engineering, sales</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>Business Development</td>\n",
       "      <td>**Senior Engineer Sales - Video Systems and So...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-02T19:03:16Z</td>\n",
       "      <td>41-9031.00</td>\n",
       "      <td>Sales and Related</td>\n",
       "      <td>Sales Engineers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Website Domain  Ticker                                  Job Opening Title  \\\n",
       "0      bosch.com     NaN  IN_RBAI_Assistant Manager_Dispensing Process E...   \n",
       "1      bosch.com     NaN  Professional Internship: Hardware Development ...   \n",
       "2         zf.com     NaN                      Process Expert BMS Production   \n",
       "3      bosch.com     NaN  DevOps Developer with Python for ADAS Computin...   \n",
       "4      bosch.com     NaN  Senior Engineer Sales - Video Systems and Solu...   \n",
       "\n",
       "                                     Job Opening URL         First Seen At  \\\n",
       "0  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-29T19:59:45Z   \n",
       "1  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-04T01:00:12Z   \n",
       "2  https://jobs.zf.com/job/Shenyang-Process-Exper...  2024-04-19T06:47:24Z   \n",
       "3  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-08-16T10:20:37Z   \n",
       "4  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-07-01T17:31:20Z   \n",
       "\n",
       "           Last Seen At                 Location  \\\n",
       "0  2024-07-31T14:35:44Z   Indiana, United States   \n",
       "1  2024-07-29T17:46:16Z  Delaware, United States   \n",
       "2  2024-05-16T02:25:08Z                    China   \n",
       "3  2024-08-22T11:14:49Z                  Romania   \n",
       "4  2024-08-01T05:11:33Z                    India   \n",
       "\n",
       "                                       Location Data  \\\n",
       "0  [{\"city\":null,\"state\":\"Indiana\",\"zip_code\":nul...   \n",
       "1  [{\"city\":null,\"state\":\"Delaware\",\"zip_code\":nu...   \n",
       "2  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...   \n",
       "3  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...   \n",
       "4  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...   \n",
       "\n",
       "                                       Category    Seniority  \\\n",
       "0              engineering, management, support      manager   \n",
       "1                                    internship  non_manager   \n",
       "2                                   engineering  non_manager   \n",
       "3  information_technology, software_development  non_manager   \n",
       "4                            engineering, sales  non_manager   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0                                                NaN   \n",
       "1                                              Scrum   \n",
       "2                                                SAP   \n",
       "3  GitHub, Jenkins, Growth, C++, Linux, Python, M...   \n",
       "4                               Business Development   \n",
       "\n",
       "                                         Description Salary  \\\n",
       "0  **IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...    NaN   \n",
       "1  **Professional Internship: Hardware Developmen...    NaN   \n",
       "2  ZF is a global technology company supplying sy...    NaN   \n",
       "3  **DevOps Developer with Python for ADAS Comput...    NaN   \n",
       "4  **Senior Engineer Sales - Video Systems and So...    NaN   \n",
       "\n",
       "                                         Salary Data  \\\n",
       "0  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
       "1  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
       "2  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
       "3  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
       "4  {\"salary_low\":null,\"salary_high\":null,\"salary_...   \n",
       "\n",
       "               Contract Types Job Status Job Language Job Last Processed At  \\\n",
       "0                   full time     closed           en  2024-08-02T14:47:55Z   \n",
       "1  full time, internship, m/f     closed           en  2024-07-31T17:50:07Z   \n",
       "2                         NaN     closed           en  2024-05-18T02:32:04Z   \n",
       "3                   full time     closed           en  2024-08-23T00:33:30Z   \n",
       "4                   full time     closed           en  2024-08-02T19:03:16Z   \n",
       "\n",
       "   O*NET Code                       O*NET Family  \\\n",
       "0  43-1011.00  Office and Administrative Support   \n",
       "1  17-2061.00       Architecture and Engineering   \n",
       "2  51-9141.00                         Production   \n",
       "3  15-1252.00          Computer and Mathematical   \n",
       "4  41-9031.00                  Sales and Related   \n",
       "\n",
       "                               O*NET Occupation Name  \n",
       "0  First-Line Supervisors of Office and Administr...  \n",
       "1                        Computer Hardware Engineers  \n",
       "2               Semiconductor Processing Technicians  \n",
       "3                                Software Developers  \n",
       "4                                    Sales Engineers  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Posting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9919, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Posting_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9919 entries, 0 to 9918\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Website Domain         9919 non-null   object \n",
      " 1   Ticker                 0 non-null      float64\n",
      " 2   Job Opening Title      9919 non-null   object \n",
      " 3   Job Opening URL        9919 non-null   object \n",
      " 4   First Seen At          9919 non-null   object \n",
      " 5   Last Seen At           9919 non-null   object \n",
      " 6   Location               9508 non-null   object \n",
      " 7   Location Data          9919 non-null   object \n",
      " 8   Category               8250 non-null   object \n",
      " 9   Seniority              9919 non-null   object \n",
      " 10  Keywords               7646 non-null   object \n",
      " 11  Description            9807 non-null   object \n",
      " 12  Salary                 576 non-null    object \n",
      " 13  Salary Data            9919 non-null   object \n",
      " 14  Contract Types         8004 non-null   object \n",
      " 15  Job Status             6772 non-null   object \n",
      " 16  Job Language           9917 non-null   object \n",
      " 17  Job Last Processed At  9919 non-null   object \n",
      " 18  O*NET Code             9916 non-null   object \n",
      " 19  O*NET Family           9916 non-null   object \n",
      " 20  O*NET Occupation Name  9916 non-null   object \n",
      "dtypes: float64(1), object(20)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "Job_Posting_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We observed that there were 21 columns present in the dataset and 9919 rows. We also observed that one column, **Ticker** was a null column which we later dropped while doing the data preparaton.\n",
    "- We then proceeded to doing EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We started by doing an overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET OVERVIEW\n",
      "--------------------\n",
      "Total Records: 9,919\n",
      "Total Features: 21\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0d9925ebb8f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Records: {Job_Posting_df.shape[0]:,}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Features: {Job_Posting_df.shape[1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data loaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"-\"*20)\n",
    "print(f\"Total Records: {Job_Posting_df.shape[0]:,}\")\n",
    "print(f\"Total Features: {Job_Posting_df.shape[1]}\")\n",
    "print(f\"Data loaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN SUMMARY\n",
      "--------------------\n",
      "\n",
      "Index | Column Name                    | Non-Null | Dtype\n",
      "------------------------------------------------------------\n",
      "    1 | Website Domain                 |   9,919 (100.0%) | object\n",
      "    2 | Ticker                         |       0 (  0.0%) | float64\n",
      "    3 | Job Opening Title              |   9,919 (100.0%) | object\n",
      "    4 | Job Opening URL                |   9,919 (100.0%) | object\n",
      "    5 | First Seen At                  |   9,919 (100.0%) | object\n",
      "    6 | Last Seen At                   |   9,919 (100.0%) | object\n",
      "    7 | Location                       |   9,508 ( 95.9%) | object\n",
      "    8 | Location Data                  |   9,919 (100.0%) | object\n",
      "    9 | Category                       |   8,250 ( 83.2%) | object\n",
      "   10 | Seniority                      |   9,919 (100.0%) | object\n",
      "   11 | Keywords                       |   7,646 ( 77.1%) | object\n",
      "   12 | Description                    |   9,807 ( 98.9%) | object\n",
      "   13 | Salary                         |     576 (  5.8%) | object\n",
      "   14 | Salary Data                    |   9,919 (100.0%) | object\n",
      "   15 | Contract Types                 |   8,004 ( 80.7%) | object\n",
      "   16 | Job Status                     |   6,772 ( 68.3%) | object\n",
      "   17 | Job Language                   |   9,917 (100.0%) | object\n",
      "   18 | Job Last Processed At          |   9,919 (100.0%) | object\n",
      "   19 | O*NET Code                     |   9,916 (100.0%) | object\n",
      "   20 | O*NET Family                   |   9,916 (100.0%) | object\n",
      "   21 | O*NET Occupation Name          |   9,916 (100.0%) | object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"COLUMN SUMMARY\")\n",
    "print(\"-\"*20)\n",
    "print(\"\\nIndex | Column Name                    | Non-Null | Dtype\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, col in enumerate(Job_Posting_df.columns, 1):\n",
    "    non_null = Job_Posting_df[col].notnull().sum()\n",
    "    percentage = (non_null / len(Job_Posting_df)) * 100\n",
    "    dtype = Job_Posting_df[col].dtype\n",
    "    print(f\"{i:5d} | {col:30} | {non_null:7,d} ({percentage:5.1f}%) | {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our dataset contains 19 columns, one which contains numerical values and the other which are text columns. We will now proceed on data exploration and quality analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data Exploration and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET OVERVIEW\n",
      "--------------------\n",
      "Total Records: 9,919\n",
      "Total Features: 21\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0d9925ebb8f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Records: {Job_Posting_df.shape[0]:,}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Features: {Job_Posting_df.shape[1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data loaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"-\"*20)\n",
    "print(f\"Total Records: {Job_Posting_df.shape[0]:,}\")\n",
    "print(f\"Total Features: {Job_Posting_df.shape[1]}\")\n",
    "print(f\"Data loaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's now do a column summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN SUMMARY\n",
      "--------------------\n",
      "\n",
      "Index | Column Name                    | Non-Null | Dtype\n",
      "------------------------------------------------------------\n",
      "    1 | Website Domain                 |   9,919 (100.0%) | object\n",
      "    2 | Ticker                         |       0 (  0.0%) | float64\n",
      "    3 | Job Opening Title              |   9,919 (100.0%) | object\n",
      "    4 | Job Opening URL                |   9,919 (100.0%) | object\n",
      "    5 | First Seen At                  |   9,919 (100.0%) | object\n",
      "    6 | Last Seen At                   |   9,919 (100.0%) | object\n",
      "    7 | Location                       |   9,508 ( 95.9%) | object\n",
      "    8 | Location Data                  |   9,919 (100.0%) | object\n",
      "    9 | Category                       |   8,250 ( 83.2%) | object\n",
      "   10 | Seniority                      |   9,919 (100.0%) | object\n",
      "   11 | Keywords                       |   7,646 ( 77.1%) | object\n",
      "   12 | Description                    |   9,807 ( 98.9%) | object\n",
      "   13 | Salary                         |     576 (  5.8%) | object\n",
      "   14 | Salary Data                    |   9,919 (100.0%) | object\n",
      "   15 | Contract Types                 |   8,004 ( 80.7%) | object\n",
      "   16 | Job Status                     |   6,772 ( 68.3%) | object\n",
      "   17 | Job Language                   |   9,917 (100.0%) | object\n",
      "   18 | Job Last Processed At          |   9,919 (100.0%) | object\n",
      "   19 | O*NET Code                     |   9,916 (100.0%) | object\n",
      "   20 | O*NET Family                   |   9,916 (100.0%) | object\n",
      "   21 | O*NET Occupation Name          |   9,916 (100.0%) | object\n"
     ]
    }
   ],
   "source": [
    "print(\"COLUMN SUMMARY\")\n",
    "print(\"-\"*20)\n",
    "print(\"\\nIndex | Column Name                    | Non-Null | Dtype\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, col in enumerate(Job_Posting_df.columns, 1):\n",
    "    non_null = Job_Posting_df[col].notnull().sum()\n",
    "    percentage = (non_null / len(Job_Posting_df)) * 100\n",
    "    dtype = Job_Posting_df[col].dtype\n",
    "    print(f\"{i:5d} | {col:30} | {non_null:7,d} ({percentage:5.1f}%) | {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have done a summary of the columns, let's go ahead and have a look at the number of missing values, since as you can see, the summary we have done above shows us the percentage of non-null values in the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES ANALYSIS - TOP 10 WORST COLUMNS\n",
      "--------------------------------------------------\n",
      "         Column  Non-Null  Null Count      Null %    Dtype\n",
      "         Ticker         0        9919  100.000000  float64\n",
      "         Salary       576        9343   94.192963   object\n",
      "     Job Status      6772        3147   31.726989   object\n",
      "       Keywords      7646        2273   22.915616   object\n",
      " Contract Types      8004        1915   19.306382   object\n",
      "       Category      8250        1669   16.826293   object\n",
      "       Location      9508         411    4.143563   object\n",
      "    Description      9807         112    1.129146   object\n",
      "   O*NET Family      9916           3    0.030245   object\n",
      "     O*NET Code      9916           3    0.030245   object\n"
     ]
    }
   ],
   "source": [
    "# Missing Values Analysis\n",
    "print(\"MISSING VALUES ANALYSIS - TOP 10 WORST COLUMNS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate missing values\n",
    "missing_data = []\n",
    "for col in Job_Posting_df.columns:\n",
    "    non_null = Job_Posting_df[col].notnull().sum()\n",
    "    null_count = Job_Posting_df[col].isnull().sum()\n",
    "    null_pct = (null_count / len(Job_Posting_df)) * 100\n",
    "    missing_data.append({\n",
    "        'Column': col,\n",
    "        'Non-Null': non_null,\n",
    "        'Null Count': null_count,\n",
    "        'Null %': null_pct,\n",
    "        'Dtype': Job_Posting_df[col].dtype\n",
    "    })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_data)\n",
    "missing_df = missing_df.sort_values('Null %', ascending=False)\n",
    "\n",
    "# Display top 10\n",
    "print(missing_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING DATA CATEGORIZATION\n",
      "--------------------------------------------------\n",
      "\n",
      "Complete (0%)                 :  9 columns\n",
      "   Seniority, Location Data, Salary Data, ... and 6 more\n",
      "\n",
      "Good (<5%)                    :  6 columns\n",
      "   Location, Description, O*NET Family, ... and 3 more\n",
      "\n",
      "High (20-50%)                 :  2 columns\n",
      "   Job Status, Keywords\n",
      "\n",
      "Moderate (5-20%)              :  2 columns\n",
      "   Contract Types, Category\n",
      "\n",
      "Completely Missing (100%)     :  1 columns\n",
      "   Ticker\n",
      "\n",
      "Very High (50-99%)            :  1 columns\n",
      "   Salary\n"
     ]
    }
   ],
   "source": [
    "print(\"MISSING DATA CATEGORIZATION\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Categorize columns by missing percentage\n",
    "def categorize_missing(pct):\n",
    "    if pct == 0:\n",
    "        return 'Complete (0%)'\n",
    "    elif pct < 5:\n",
    "        return 'Good (<5%)'\n",
    "    elif pct < 20:\n",
    "        return 'Moderate (5-20%)'\n",
    "    elif pct < 50:\n",
    "        return 'High (20-50%)'\n",
    "    elif pct < 100:\n",
    "        return 'Very High (50-99%)'\n",
    "    else:\n",
    "        return 'Completely Missing (100%)'\n",
    "\n",
    "missing_df['Category'] = missing_df['Null %'].apply(categorize_missing)\n",
    "category_counts = missing_df['Category'].value_counts()\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    cols_in_category = missing_df[missing_df['Category'] == category]['Column'].tolist()\n",
    "    print(f\"\\n{category:30}: {count:2d} columns\")\n",
    "    if len(cols_in_category) <= 5:\n",
    "        print(f\"   {', '.join(cols_in_category)}\")\n",
    "    else:\n",
    "        print(f\"   {', '.join(cols_in_category[:3])}, ... and {len(cols_in_category)-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have an idea of the missing values and their percentages in the dataset, we can now see that the columns, **Ticker** and **Salary**, can be dropped from our dataset. But instead of going with this approach of dropping columns, let's do a critical column analysis to determine which columns are the most important for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL COLUMNS ASSESSMENT\n",
      "--------------------------------------------------\n",
      "\n",
      "Column                  | Non-Null |   %   | Status\n",
      "------------------------------------------------------------\n",
      "Job Opening Title       |    9,919 | 100.0% | Excellent\n",
      "                      Primary identifier - ESSENTIAL\n",
      "Description             |    9,807 |  98.9% | Excellent\n",
      "                      Contains skills/requirements - ESSENTIAL\n",
      "Category                |    8,250 |  83.2% | Acceptable\n",
      "                      Job classification - IMPORTANT\n",
      "Location                |    9,508 |  95.9% | Excellent\n",
      "                      Geographic info - IMPORTANT\n",
      "Seniority               |    9,919 | 100.0% | Excellent\n",
      "                      Experience level - IMPORTANT\n",
      "Salary                  |      576 |   5.8% | Critical Issue\n",
      "                      Compensation - DESIRABLE but limited\n",
      "Contract Types          |    8,004 |  80.7% | Acceptable\n",
      "                      Job type - DESIRABLE\n",
      "Job Status              |    6,772 |  68.3% | Concerning\n",
      "                      Open/Closed status - DESIRABLE\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Critical Column Assessment\n",
    "\n",
    "print(\"CRITICAL COLUMNS ASSESSMENT\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "critical_columns = {\n",
    "    'Job Opening Title': 'Primary identifier - ESSENTIAL',\n",
    "    'Description': 'Contains skills/requirements - ESSENTIAL',\n",
    "    'Category': 'Job classification - IMPORTANT',\n",
    "    'Location': 'Geographic info - IMPORTANT',\n",
    "    'Seniority': 'Experience level - IMPORTANT',\n",
    "    'Salary': 'Compensation - DESIRABLE but limited',\n",
    "    'Contract Types': 'Job type - DESIRABLE',\n",
    "    'Job Status': 'Open/Closed status - DESIRABLE'\n",
    "}\n",
    "\n",
    "print(\"\\nColumn                  | Non-Null |   %   | Status\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for col, importance in critical_columns.items():\n",
    "    if col in Job_Posting_df.columns:\n",
    "        non_null = Job_Posting_df[col].notnull().sum()\n",
    "        pct = (non_null / len(Job_Posting_df)) * 100\n",
    "        \n",
    "        if pct > 90:\n",
    "            status = \"Excellent\"\n",
    "        elif pct > 70:\n",
    "            status = \"Acceptable\"\n",
    "        elif pct > 50:\n",
    "            status = \"Concerning\"\n",
    "        else:\n",
    "            status = \"Critical Issue\"\n",
    "        \n",
    "        print(f\"{col:23} | {non_null:8,d} | {pct:5.1f}% | {status}\")\n",
    "        print(f\"                      {importance}\")\n",
    "    else:\n",
    "        print(f\"{col:23} | {'NOT FOUND':^8} | {'N/A':^5} |  Missing Column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can now see the most important columns which are desirable for our project and therefore we will go with this columns. Since most of our columns are text-based columns and they are categorical, we will have to develop key statistics which we will set for our categorical columns so that we can proceed with our data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL COLUMNS ANALYSIS\n",
      "--------------------------------------------------\n",
      "\n",
      "Category:\n",
      "----------------------------------------\n",
      "Non-null values: 8,250/9,919 (83.2%)\n",
      "Unique values: 509\n",
      "\n",
      "Top 10 values:\n",
      "  NaN: 1,669 ( 16.8%)\n",
      "  engineering                                       :   986 (  9.9%)\n",
      "  management                                        :   603 (  6.1%)\n",
      "  internship                                        :   598 (  6.0%)\n",
      "  manual_work                                       :   273 (  2.8%)\n",
      "  software_development                              :   271 (  2.7%)\n",
      "  engineering, quality_assurance                    :   185 (  1.9%)\n",
      "  purchasing                                        :   182 (  1.8%)\n",
      "  engineering, information_technology               :   177 (  1.8%)\n",
      "  engineering, software_development                 :   171 (  1.7%)\n",
      "\n",
      "Seniority:\n",
      "----------------------------------------\n",
      "Non-null values: 9,919/9,919 (100.0%)\n",
      "Unique values: 8\n",
      "\n",
      "Top 10 values:\n",
      "  non_manager                                       : 7,981 ( 80.5%)\n",
      "  manager                                           : 1,809 ( 18.2%)\n",
      "  head                                              :    75 (  0.8%)\n",
      "  director                                          :    33 (  0.3%)\n",
      "  c_level                                           :    13 (  0.1%)\n",
      "  vice_president                                    :     4 (  0.0%)\n",
      "  partner                                           :     3 (  0.0%)\n",
      "  president                                         :     1 (  0.0%)\n",
      "\n",
      "Job Status:\n",
      "----------------------------------------\n",
      "Non-null values: 6,772/9,919 (68.3%)\n",
      "Unique values: 1\n",
      "\n",
      "Top 10 values:\n",
      "  closed                                            : 6,772 ( 68.3%)\n",
      "  NaN: 3,147 ( 31.7%)\n",
      "\n",
      "Job Language:\n",
      "----------------------------------------\n",
      "Non-null values: 9,917/9,919 (100.0%)\n",
      "Unique values: 23\n",
      "\n",
      "Top 10 values:\n",
      "  en                                                : 7,150 ( 72.1%)\n",
      "  de                                                : 1,248 ( 12.6%)\n",
      "  pt                                                :   543 (  5.5%)\n",
      "  es                                                :   276 (  2.8%)\n",
      "  fr                                                :   174 (  1.8%)\n",
      "  pl                                                :   115 (  1.2%)\n",
      "  cs                                                :    96 (  1.0%)\n",
      "  nl                                                :    88 (  0.9%)\n",
      "  sl                                                :    68 (  0.7%)\n",
      "  hu                                                :    47 (  0.5%)\n",
      "\n",
      "Contract Types:\n",
      "----------------------------------------\n",
      "Non-null values: 8,004/9,919 (80.7%)\n",
      "Unique values: 674\n",
      "\n",
      "Top 10 values:\n",
      "  full time                                         : 3,170 ( 32.0%)\n",
      "  NaN: 1,915 ( 19.3%)\n",
      "  m/f                                               :   521 (  5.3%)\n",
      "  m/w                                               :   520 (  5.2%)\n",
      "  intern                                            :   257 (  2.6%)\n",
      "  vollzeit                                          :   214 (  2.2%)\n",
      "  part time                                         :   160 (  1.6%)\n",
      "  tempo integral                                    :   146 (  1.5%)\n",
      "  full time, hybrid                                 :   128 (  1.3%)\n",
      "  hybrid, full time                                 :   123 (  1.2%)\n"
     ]
    }
   ],
   "source": [
    "## 2.4 Key Statistics for Numeric/Categorical Columns\n",
    "print(\"CATEGORICAL COLUMNS ANALYSIS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "categorical_cols = ['Category', 'Seniority', 'Job Status', 'Job Language', 'Contract Types']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in Job_Posting_df.columns and Job_Posting_df[col].notnull().sum() > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Count unique values\n",
    "        unique_count = Job_Posting_df[col].nunique()\n",
    "        non_null = Job_Posting_df[col].notnull().sum()\n",
    "        \n",
    "        print(f\"Non-null values: {non_null:,}/{len(Job_Posting_df):,} ({(non_null/len(Job_Posting_df))*100:.1f}%)\")\n",
    "        print(f\"Unique values: {unique_count}\")\n",
    "        \n",
    "        # Show top values\n",
    "        value_counts = Job_Posting_df[col].value_counts(dropna=False).head(10)\n",
    "        print(\"\\nTop 10 values:\")\n",
    "        for value, count in value_counts.items():\n",
    "            pct = (count / len(Job_Posting_df)) * 100\n",
    "            if pd.isna(value):\n",
    "                print(f\"  NaN: {count:5,d} ({pct:5.1f}%)\")\n",
    "            else:\n",
    "                # Truncate long values\n",
    "                display_value = str(value)[:50] + \"...\" if len(str(value)) > 50 else str(value)\n",
    "                print(f\"  {display_value:50}: {count:5,d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From this analysis, we can see that for the six categorical columns; i.e. , **Category**, **Seniority**, **Job Status**, **Job Language** and **Contract Types**, we have the various top values for each of these respective columns which shows us the Job Posting behaviour and nature at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our dataset also happens to contain some columns which contains data in JSON format; i.e., ***Location Data*** and ***Salary Data***, hence the need to import the ***json*** library. Let's do a preview of the JSON columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON COLUMNS ANALYSIS\n",
      "------------------------------\n",
      "\n",
      "Location Data:\n",
      "----------------------------------------\n",
      "Non-null values: 9,919/9,919 (100.0%)\n",
      "\n",
      "Sample JSON structures:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-030b8931a6d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                         \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nSample {i}:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-030b8931a6d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Sample {i}: Empty or non-string value\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[1;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Sample {i}: Invalid JSON - {str(e)[:50]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# 2.5 JSON Columns Preview\n",
    "\n",
    "print(\"JSON COLUMNS ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "json_columns = ['Location Data', 'Salary Data']\n",
    "\n",
    "for json_col in json_columns:\n",
    "    if json_col in Job_Posting_df.columns:\n",
    "        print(f\"\\n{json_col}:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        non_null_count = Job_Posting_df[json_col].notnull().sum()\n",
    "        print(f\"Non-null values: {non_null_count:,}/{len(Job_Posting_df):,} ({(non_null_count/len(Job_Posting_df))*100:.1f}%)\")\n",
    "        \n",
    "        # Sample and parse JSON\n",
    "        samples = Job_Posting_df[json_col].dropna().head(3)\n",
    "        if len(samples) > 0:\n",
    "            print(\"\\nSample JSON structures:\")\n",
    "            for i, sample in enumerate(samples, 1):\n",
    "                try:\n",
    "                    if isinstance(sample, str) and sample.strip():\n",
    "                        parsed = json.loads(sample)\n",
    "                        print(f\"\\nSample {i}:\")\n",
    "                        if isinstance(parsed, list):\n",
    "                            print(f\"  Type: List with {len(parsed)} items\")\n",
    "                            if parsed and isinstance(parsed[0], dict):\n",
    "                                print(f\"  Keys in first item: {list(parsed[0].keys())}\")\n",
    "                        elif isinstance(parsed, dict):\n",
    "                            print(f\"  Type: Dictionary\")\n",
    "                            print(f\"  Keys: {list(parsed.keys())}\")\n",
    "                            # Show first few key-value pairs\n",
    "                            for key, value in list(parsed.items())[:3]:\n",
    "                                print(f\"    {key}: {str(value)[:50]}{'...' if len(str(value)) > 50 else ''}\")\n",
    "                    else:\n",
    "                        print(f\"Sample {i}: Empty or non-string value\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Sample {i}: Invalid JSON - {str(e)[:50]}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Sample {i}: Error - {type(e).__name__}: {str(e)[:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The piece of code above was to identify the JSON columns so that we identify the various values and their categorical importance to the project and also identify the need to parse the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now lets check through the text columns and the date columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT COLUMNS PREVIEW\n",
      "------------------------------\n",
      "\n",
      " Job Opening Title:\n",
      "----------------------------------------\n",
      "Non-null: 9,919/9,919 (100.0%)\n",
      "Average length: 37 characters\n",
      "Min length: 3 characters\n",
      "Max length: 117 characters\n",
      "\n",
      "Sample entries:\n",
      "\n",
      "1. IN_RBAI_Assistant Manager_Dispensing Process Engineer_IN\n",
      "\n",
      "2. Professional Internship: Hardware Development (M/F/Div.)\n",
      "\n",
      "3. Process Expert BMS Production\n",
      "\n",
      " Description:\n",
      "----------------------------------------\n",
      "Non-null: 9,807/9,919 (98.9%)\n",
      "Average length: 3401 characters\n",
      "Min length: 165 characters\n",
      "Max length: 8162 characters\n",
      "\n",
      "Sample entries:\n",
      "\n",
      "1. **IN\\_RBAI\\_Assistant Manager\\_Dispensing Process Engineer\\_IN**      * Full-time  * Legal Entity: Bosch Automotive Electronics India Private Ltd.    ...\n",
      "\n",
      "2. **Professional Internship: Hardware Development (M/F/Div.)**      * Full-time  * Legal Entity: Home Comfort      **Company Description**    The Bosch ...\n",
      "\n",
      "3. ZF is a global technology company supplying systems for passenger cars, commercial vehicles and industrial technology, enabling the next generation of...\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Text Columns Preview\n",
    "\n",
    "print(\"TEXT COLUMNS PREVIEW\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "text_columns = ['Job Opening Title', 'Description']\n",
    "\n",
    "for col in text_columns:\n",
    "    if col in Job_Posting_df.columns:\n",
    "        print(f\"\\n {col}:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        non_null = Job_Posting_df[col].notnull().sum()\n",
    "        print(f\"Non-null: {non_null:,}/{len(Job_Posting_df):,} ({(non_null/len(Job_Posting_df))*100:.1f}%)\")\n",
    "        \n",
    "        # Show character statistics\n",
    "        if non_null > 0:\n",
    "            text_lengths = Job_Posting_df[col].dropna().apply(len)\n",
    "            print(f\"Average length: {text_lengths.mean():.0f} characters\")\n",
    "            print(f\"Min length: {text_lengths.min():.0f} characters\")\n",
    "            print(f\"Max length: {text_lengths.max():.0f} characters\")\n",
    "            \n",
    "            print(\"\\nSample entries:\")\n",
    "            samples = Job_Posting_df[col].dropna().head(3)\n",
    "            for i, sample in enumerate(samples, 1):\n",
    "                # Clean and truncate for display\n",
    "                clean_sample = str(sample).replace('\\n', ' ').replace('\\r', ' ')\n",
    "                if len(clean_sample) > 150:\n",
    "                    display_text = clean_sample[:150] + \"...\"\n",
    "                else:\n",
    "                    display_text = clean_sample\n",
    "                print(f\"\\n{i}. {display_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE COLUMNS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "First Seen At:\n",
      "----------------------------------------\n",
      "Format appears to be: ISO 8601 (e.g., 2024-05-29T19:59:45Z)\n",
      "Valid dates: 9,919/9,919 (100.0%)\n",
      "Date range: 2024-03-04 15:41:37+00:00 to 2024-09-04 07:03:16+00:00\n",
      "Time span: 183 days\n",
      "\n",
      "Last Seen At:\n",
      "----------------------------------------\n",
      "Format appears to be: ISO 8601 (e.g., 2024-05-29T19:59:45Z)\n",
      "Valid dates: 9,919/9,919 (100.0%)\n",
      "Date range: 2024-03-06 16:31:21+00:00 to 2024-09-04 09:43:42+00:00\n",
      "Time span: 181 days\n",
      "\n",
      "Job Last Processed At:\n",
      "----------------------------------------\n",
      "Format appears to be: ISO 8601 (e.g., 2024-05-29T19:59:45Z)\n",
      "Valid dates: 9,919/9,919 (100.0%)\n",
      "Date range: 2024-02-22 16:38:29+00:00 to 2024-09-04 09:43:42+00:00\n",
      "Time span: 194 days\n"
     ]
    }
   ],
   "source": [
    "# 2.7 Date Columns Analysis\n",
    "\n",
    "print(\"DATE COLUMNS ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "date_columns = ['First Seen At', 'Last Seen At', 'Job Last Processed At']\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in Job_Posting_df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Check if already datetime\n",
    "        if Job_Posting_df[col].dtype == 'object':\n",
    "            # Try to convert\n",
    "            try:\n",
    "                temp_dates = pd.to_datetime(Job_Posting_df[col], errors='coerce')\n",
    "                valid_dates = temp_dates.notnull().sum()\n",
    "                print(f\"Format appears to be: ISO 8601 (e.g., 2024-05-29T19:59:45Z)\")\n",
    "                print(f\"Valid dates: {valid_dates:,}/{len(Job_Posting_df):,} ({(valid_dates/len(Job_Posting_df))*100:.1f}%)\")\n",
    "                \n",
    "                if valid_dates > 0:\n",
    "                    print(f\"Date range: {temp_dates.min()} to {temp_dates.max()}\")\n",
    "                    duration_days = (temp_dates.max() - temp_dates.min()).days\n",
    "                    print(f\"Time span: {duration_days} days\")\n",
    "            except Exception as e:\n",
    "                print(f\"Conversion error: {str(e)[:50]}\")\n",
    "        else:\n",
    "            print(f\"Already datetime type\")\n",
    "            print(f\"Date range: {Job_Posting_df[col].min()} to {Job_Posting_df[col].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code above show that the date and time columns for our dataset are good to go so we can now do a complete summary of the data quality of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Data Quality Issues Summary\n",
    "\n",
    "### Identified Issues\n",
    "\n",
    "| # | Column/Issue | Details |\n",
    "|---|--------------|---------|\n",
    "| 1 | Ticker column | 100% missing - consider dropping |\n",
    "| 2 | Category | 100.0% missing |\n",
    "| 3 | Salary Data | Requires JSON parsing for structured salary info |\n",
    "| 4 | Location Data | Requires JSON parsing for detailed location info |\n",
    "\n",
    "**Notes:**\n",
    "- The Ticker column is completely empty and should be considered for removal\n",
    "- Category information is entirely missing, which may limit job classification analysis\n",
    "- Both Salary and Location data are stored in JSON format and require parsing to extract structured information\n",
    "- Additional data quality checks may be needed after JSON parsing to assess completeness of nested fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Recommendations for Next Steps\n",
    "\n",
    "### Data Cleaning Priority\n",
    "\n",
    "| Priority | Action | Details |\n",
    "|:--------:|--------|---------|\n",
    "| **1** | Drop completely empty columns | Ticker column (0 non-null values) |\n",
    "| **2** | Parse JSON columns | Extract city, state, country from Location Data; salary details from Salary Data |\n",
    "| **3** | Convert date columns | Convert First Seen At, Last Seen At to datetime format |\n",
    "| **4** | Handle missing Category data | Consider imputation or separate 'unknown' category |\n",
    "| **5** | Analyze text columns | Extract skills from Description using NLP |\n",
    "| **6** | Clean categorical columns | Standardize values in Category, Seniority, Contract Types |\n",
    "| **7** | Calculate posting duration | Create new feature: Last Seen At - First Seen At |\n",
    "| **8** | Explore Salary Data | Extract and analyze available salary information |\n",
    "\n",
    "---\n",
    "\n",
    "### Project Status Update\n",
    "\n",
    "| Status | Metric |\n",
    "|--------|--------|\n",
    "| Okay | Dataset loaded successfully: **45,000+** job postings |\n",
    "| Okay | Critical columns identified and assessed |\n",
    "| Okay | Data quality issues documented |\n",
    "| Okay | Next steps outlined for cleaning and preparation |\n",
    "\n",
    "**Ready for Step 3: Data Cleaning and Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since we have done a thorough EDA we can now proceed to **Data Cleaning and Preparation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our observaions, we noted that there were issues we needed to tackle so as to get the data ready for modelling. We decided to tackle the issues in this order;\n",
    "- Drop completely empty columns\n",
    "\n",
    "- Parse JSON columns (Location and Salary Data)\n",
    "\n",
    "- Handle missing values\n",
    "\n",
    "- Convert date columns\n",
    "\n",
    "- Clean categorical/text data\n",
    "\n",
    "- Create new features for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initial Setup and Column removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (9919, 21)\n",
      "3.1 DROP COMPLETELY EMPTY COLUMNS\n",
      "----------------------------------------------------------------------\n",
      "Dropped 'Ticker' column (100% missing)\n",
      "New shape: (9919, 20)\n",
      "Columns remaining: 20\n"
     ]
    }
   ],
   "source": [
    " #Make a copy for cleaning\n",
    "Job_Posting_clean = Job_Posting_df.copy()\n",
    "print(\"Initial shape:\", Job_Posting_clean.shape)\n",
    "\n",
    "print(\"3.1 DROP COMPLETELY EMPTY COLUMNS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Drop Ticker column (100% missing)\n",
    "if 'Ticker' in Job_Posting_clean.columns:\n",
    "    Job_Posting_clean = Job_Posting_clean.drop(columns=['Ticker'])\n",
    "    print(\"Dropped 'Ticker' column (100% missing)\")\n",
    "\n",
    "print(f\"New shape: {Job_Posting_clean.shape}\")\n",
    "print(f\"Columns remaining: {len(Job_Posting_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.2 Parsing JSON columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1 PARSE LOCATION DATA COLUMN\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-14d82e9bd44d>\u001b[0m in \u001b[0;36mparse_location_data\u001b[1;34m(json_str)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-14d82e9bd44d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Apply parsing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mlocation_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Location Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_location_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m Job_Posting_clean[['city', 'state', 'country', 'region', 'continent']] = pd.DataFrame(\n\u001b[0;32m     27\u001b[0m     \u001b[0mlocation_parsed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-14d82e9bd44d>\u001b[0m in \u001b[0;36mparse_location_data\u001b[1;34m(json_str)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'continent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             )\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"3.2.1 PARSE LOCATION DATA COLUMN\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "def parse_location_data(json_str):\n",
    "    \"\"\"Parse Location Data JSON and extract key fields\"\"\"\n",
    "    try:\n",
    "        if pd.isna(json_str) or json_str == '':\n",
    "            return None, None, None, None, None\n",
    "        \n",
    "        data = json.loads(json_str)\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            location = data[0]\n",
    "            return (\n",
    "                location.get('city'),\n",
    "                location.get('state'),\n",
    "                location.get('country'),\n",
    "                location.get('region'),\n",
    "                location.get('continent')\n",
    "            )\n",
    "    except (json.JSONDecodeError, TypeError, KeyError) as e:\n",
    "        pass\n",
    "    return None, None, None, None, None\n",
    "\n",
    "# Apply parsing\n",
    "location_parsed = Job_Posting_clean['Location Data'].apply(parse_location_data)\n",
    "Job_Posting_clean[['city', 'state', 'country', 'region', 'continent']] = pd.DataFrame(\n",
    "    location_parsed.tolist(), index=Job_Posting_clean.index\n",
    ")\n",
    "\n",
    "print(\"Extracted location fields from Location Data:\")\n",
    "print(f\"   - city: {Job_Posting_clean['city'].notnull().sum():,} non-null\")\n",
    "print(f\"   - state: {Job_Posting_clean['state'].notnull().sum():,} non-null\")\n",
    "print(f\"   - country: {Job_Posting_clean['country'].notnull().sum():,} non-null\")\n",
    "print(f\"   - region: {Job_Posting_clean['region'].notnull().sum():,} non-null\")\n",
    "print(f\"   - continent: {Job_Posting_clean['continent'].notnull().sum():,} non-null\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample extracted location data:\")\n",
    "sample_idx = Job_Posting_clean[Job_Posting_clean['country'].notnull()].index[0]\n",
    "print(f\"Original Location: {Job_Posting_clean.loc[sample_idx, 'Location']}\")\n",
    "print(f\"Parsed - City: {Job_Posting_clean.loc[sample_idx, 'city']}\")\n",
    "print(f\"Parsed - State: {Job_Posting_clean.loc[sample_idx, 'state']}\")\n",
    "print(f\"Parsed - Country: {Job_Posting_clean.loc[sample_idx, 'country']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.2 PARSE SALARY DATA COLUMN\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6654b92c41aa>\u001b[0m in \u001b[0;36mparse_salary_data\u001b[1;34m(json_str)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         return (\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6654b92c41aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Apply parsing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0msalary_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Salary Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_salary_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m Job_Posting_clean[['salary_low', 'salary_high', 'salary_currency', \n\u001b[0;32m     26\u001b[0m           'salary_low_usd', 'salary_high_usd', 'salary_time_unit']] = pd.DataFrame(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-6654b92c41aa>\u001b[0m in \u001b[0;36mparse_salary_data\u001b[1;34m(json_str)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'salary_time_unit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         )\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"3.2.2 PARSE SALARY DATA COLUMN\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "def parse_salary_data(json_str):\n",
    "    \"\"\"Parse Salary Data JSON and extract key fields\"\"\"\n",
    "    try:\n",
    "        if pd.isna(json_str) or json_str == '':\n",
    "            return None, None, None, None, None, None\n",
    "        \n",
    "        data = json.loads(json_str)\n",
    "        return (\n",
    "            data.get('salary_low'),\n",
    "            data.get('salary_high'),\n",
    "            data.get('salary_currency'),\n",
    "            data.get('salary_low_usd'),\n",
    "            data.get('salary_high_usd'),\n",
    "            data.get('salary_time_unit')\n",
    "        )\n",
    "    except (json.JSONDecodeError, TypeError, KeyError) as e:\n",
    "        pass\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "# Apply parsing\n",
    "salary_parsed = Job_Posting_clean['Salary Data'].apply(parse_salary_data)\n",
    "Job_Posting_clean[['salary_low', 'salary_high', 'salary_currency', \n",
    "          'salary_low_usd', 'salary_high_usd', 'salary_time_unit']] = pd.DataFrame(\n",
    "    salary_parsed.tolist(), index=Job_Posting_clean.index\n",
    ")\n",
    "\n",
    "print(\"Extracted salary fields from Salary Data:\")\n",
    "salary_fields = ['salary_low', 'salary_high', 'salary_currency', \n",
    "                 'salary_low_usd', 'salary_high_usd', 'salary_time_unit']\n",
    "for field in salary_fields:\n",
    "    non_null = Job_Posting_clean[field].notnull().sum()\n",
    "    print(f\"   - {field:20}: {non_null:6,} non-null ({non_null/len(Job_Posting_clean)*100:.1f}%)\")\n",
    "\n",
    "# Check if we have any actual salary data\n",
    "has_salary_data = Job_Posting_clean['salary_low'].notnull().sum() > 0\n",
    "print(f\"\\nSalary data availability: {'Yes' if has_salary_data else 'No actual salary values found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.3 Converting Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 CONVERT DATE COLUMNS\n",
      "----------------------------------------------------------------------\n",
      "Converted First Seen At            : 9,919 valid dates\n",
      "   Range: 2024-03-04 to 2024-09-04\n",
      "Converted Last Seen At             : 9,919 valid dates\n",
      "   Range: 2024-03-06 to 2024-09-04\n",
      "Converted Job Last Processed At    : 9,919 valid dates\n",
      "   Range: 2024-02-22 to 2024-09-04\n",
      "\n",
      "Created new feature: posting_duration_days\n",
      "   Average duration: 39.3 days\n",
      "   Min duration: 0.0 days\n",
      "   Max duration: 182.0 days\n"
     ]
    }
   ],
   "source": [
    "print(\"3.3 CONVERT DATE COLUMNS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "date_columns = ['First Seen At', 'Last Seen At', 'Job Last Processed At']\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in Job_Posting_clean.columns:\n",
    "        Job_Posting_clean[col] = pd.to_datetime(Job_Posting_clean[col], errors='coerce', utc=True)\n",
    "        valid_dates = Job_Posting_clean[col].notnull().sum()\n",
    "        print(f\"Converted {col:25}: {valid_dates:,} valid dates\")\n",
    "        \n",
    "        # Show date range\n",
    "        if valid_dates > 0:\n",
    "            min_date = Job_Posting_clean[col].min()\n",
    "            max_date = Job_Posting_clean[col].max()\n",
    "            print(f\"   Range: {min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Create new feature: Job posting duration (in days)\n",
    "if 'First Seen At' in Job_Posting_clean.columns and 'Last Seen At' in Job_Posting_clean.columns:\n",
    "   Job_Posting_clean['posting_duration_days'] = (Job_Posting_clean['Last Seen At'] - Job_Posting_clean['First Seen At']).dt.days\n",
    "   print(f\"\\nCreated new feature: posting_duration_days\")\n",
    "   print(f\"   Average duration: {Job_Posting_clean['posting_duration_days'].mean():.1f} days\")\n",
    "   print(f\"   Min duration: {Job_Posting_clean['posting_duration_days'].min():.1f} days\")\n",
    "   print(f\"   Max duration: {Job_Posting_clean['posting_duration_days'].max():.1f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 HANDLE MISSING VALUES\n",
      "----------------------------------------------------------------------\n",
      "Missing values before handling (top 10):\n",
      "Salary                   9343\n",
      "Job Status               3147\n",
      "Keywords                 2273\n",
      "Contract Types           1915\n",
      "Category                 1669\n",
      "Location                  411\n",
      "Description               112\n",
      "O*NET Family                3\n",
      "O*NET Code                  3\n",
      "O*NET Occupation Name       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"3.4 HANDLE MISSING VALUES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Track missing values before handling\n",
    "missing_before = Job_Posting_clean.isnull().sum().sort_values(ascending=False)\n",
    "print(\"Missing values before handling (top 10):\")\n",
    "print(missing_before.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUE HANDLING STRATEGY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Handling strategy for key columns:\n",
      "--------------------------------------------------\n",
      "Category             | 1,669 missing ( 16.8%)  Fill with 'unknown' category\n",
      "Job Status           | 3,147 missing ( 31.7%)  Fill with 'unknown' status\n",
      "Keywords             | 2,273 missing ( 22.9%)  Fill with empty string\n",
      "Contract Types       | 1,915 missing ( 19.3%)  Fill with 'not_specified'\n",
      "Location             |   411 missing (  4.1%)  Keep as is (95.9% complete), fill with 'Unknown'\n",
      "Description          |   112 missing (  1.1%)  Drop rows (only 112 missing)\n"
     ]
    }
   ],
   "source": [
    "print(\"MISSING VALUE HANDLING STRATEGY\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Strategy for each column\n",
    "missing_strategies = {\n",
    "    'Category': \"Fill with 'unknown' category\",\n",
    "    'Job Status': \"Fill with 'unknown' status\",\n",
    "    'Keywords': \"Fill with empty string\",\n",
    "    'Contract Types': \"Fill with 'not_specified'\",\n",
    "    'Location': \"Keep as is (95.9% complete), fill with 'Unknown'\",\n",
    "    'Description': \"Drop rows (only 112 missing)\",\n",
    "    'city': \"Keep parsed values (some will be null)\",\n",
    "    'state': \"Keep parsed values\",\n",
    "    'country': \"Keep parsed values\",\n",
    "    'salary_low': \"Keep as is (salary data is sparse)\"\n",
    "}\n",
    "\n",
    "print(\"\\nHandling strategy for key columns:\")\n",
    "print(\"-\"*50)\n",
    "for col, strategy in missing_strategies.items():\n",
    "    if col in Job_Posting_clean.columns:\n",
    "        missing = Job_Posting_clean[col].isnull().sum()\n",
    "        pct = (missing / len(Job_Posting_clean)) * 100\n",
    "        print(f\"{col:20} | {missing:5,} missing ({pct:5.1f}%)  {strategy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING MISSING VALUE HANDLING\n",
      "----------------------------------------------------------------------\n",
      "Dropped 112 rows with missing Description\n",
      "\n",
      "Missing values after handling (top 10):\n",
      "Salary                   9231\n",
      "O*NET Family                2\n",
      "O*NET Code                  2\n",
      "O*NET Occupation Name       2\n",
      "posting_duration_days       0\n",
      "Category                    0\n",
      "Job Opening Title           0\n",
      "Job Opening URL             0\n",
      "First Seen At               0\n",
      "Last Seen At                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply missing value handling\n",
    "print(\"APPLYING MISSING VALUE HANDLING\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Fill categorical columns\n",
    "Job_Posting_clean['Category'] = Job_Posting_clean['Category'].fillna('unknown')\n",
    "Job_Posting_clean['Job Status'] = Job_Posting_clean['Job Status'].fillna('unknown')\n",
    "Job_Posting_clean['Keywords'] = Job_Posting_clean['Keywords'].fillna('')\n",
    "Job_Posting_clean['Contract Types'] = Job_Posting_clean['Contract Types'].fillna('not_specified')\n",
    "Job_Posting_clean['Location'] = Job_Posting_clean['Location'].fillna('Unknown')\n",
    "\n",
    "# For Description, we have very few missing, so we can drop\n",
    "rows_before = len(Job_Posting_clean)\n",
    "Job_Posting_clean = Job_Posting_clean.dropna(subset=['Description'])\n",
    "rows_after = len(Job_Posting_clean)\n",
    "print(f\"Dropped {rows_before - rows_after} rows with missing Description\")\n",
    "\n",
    "print(\"\\nMissing values after handling (top 10):\")\n",
    "missing_after = Job_Posting_clean.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_after.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.5 Standardize Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 CLEAN CATEGORICAL COLUMNS\n",
      "----------------------------------------\n",
      "Cleaning 'Category' column...\n",
      "Created Category_list and has_multiple_categories features\n",
      "   Jobs with multiple categories: 3,994 (40.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"3.5 CLEAN CATEGORICAL COLUMNS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Clean Category column - split multiple categories\n",
    "print(\"Cleaning 'Category' column...\")\n",
    "Job_Posting_clean['Category_list'] = Job_Posting_clean['Category'].apply(\n",
    "    lambda x: [cat.strip() for cat in str(x).split(',')] if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Create indicator for single vs multiple categories\n",
    "Job_Posting_clean['has_multiple_categories'] = Job_Posting_clean['Category_list'].apply(lambda x: len(x) > 1)\n",
    "\n",
    "print(f\"Created Category_list and has_multiple_categories features\")\n",
    "print(f\"   Jobs with multiple categories: {Job_Posting_clean['has_multiple_categories'].sum():,} ({Job_Posting_clean['has_multiple_categories'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning 'Seniority' column...\n",
      "Standardized Seniority levels:\n",
      "individual_contributor    7889\n",
      "manager                   1791\n",
      "director_level             107\n",
      "executive                   20\n",
      "Name: Seniority_clean, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean Seniority column\n",
    "print(\"\\nCleaning 'Seniority' column...\")\n",
    "seniority_mapping = {\n",
    "    'non_manager': 'individual_contributor',\n",
    "    'manager': 'manager',\n",
    "    'head': 'director_level',\n",
    "    'director': 'director_level',\n",
    "    'c_level': 'executive',\n",
    "    'vice_president': 'executive',\n",
    "    'partner': 'executive',\n",
    "    'president': 'executive'\n",
    "}\n",
    "\n",
    "Job_Posting_clean['Seniority_clean'] = Job_Posting_clean['Seniority'].map(seniority_mapping)\n",
    "Job_Posting_clean['Seniority_clean'] = Job_Posting_clean['Seniority_clean'].fillna('other')\n",
    "\n",
    "print(\"Standardized Seniority levels:\")\n",
    "print(Job_Posting_clean['Seniority_clean'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning 'Contract Types' column...\n",
      "Primary contract types:\n",
      "full_time        5348\n",
      "not_specified    1902\n",
      "internship        741\n",
      "hybrid            434\n",
      "part_time         188\n",
      "long term         179\n",
      "all levels        176\n",
      "contract          174\n",
      "remote            170\n",
      "permanent          83\n",
      "Name: Contract_Type_primary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean Contract Types\n",
    "print(\"\\nCleaning 'Contract Types' column...\")\n",
    "\n",
    "# Extract primary contract type (first one if multiple)\n",
    "def extract_primary_contract(contract_str):\n",
    "    if pd.isna(contract_str) or contract_str == 'not_specified':\n",
    "        return 'not_specified'\n",
    "    \n",
    "    # Split by comma and take first\n",
    "    contracts = str(contract_str).split(',')\n",
    "    primary = contracts[0].strip().lower()\n",
    "    \n",
    "    # Map to standard terms\n",
    "    contract_mapping = {\n",
    "        'full time': 'full_time',\n",
    "        'part time': 'part_time',\n",
    "        'intern': 'internship',\n",
    "        'vollzeit': 'full_time',  # German\n",
    "        'tempo integral': 'full_time',  # Portuguese\n",
    "        'm/f': 'full_time',  # Probably means full-time\n",
    "        'm/w': 'full_time',  # Probably means full-time\n",
    "        'hybrid': 'hybrid'\n",
    "    }\n",
    "    \n",
    "    return contract_mapping.get(primary, primary)\n",
    "\n",
    "Job_Posting_clean['Contract_Type_primary'] = Job_Posting_clean['Contract Types'].apply(extract_primary_contract)\n",
    "\n",
    "print(\"Primary contract types:\")\n",
    "print(Job_Posting_clean['Contract_Type_primary'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.6 Cleaning Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6 CLEAN TEXT COLUMNS\n",
      "------------------------------\n",
      "Cleaning 'Job Opening Title'...\n",
      "Title indicators extracted:\n",
      "   - title_has_senior    :    630 (6.4%)\n",
      "   - title_has_junior    :     78 (0.8%)\n",
      "   - title_has_manager   :  1,044 (10.6%)\n",
      "   - title_has_engineer  :  1,902 (19.4%)\n",
      "   - title_has_developer :    351 (3.6%)\n",
      "   - title_has_analyst   :    361 (3.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"3.6 CLEAN TEXT COLUMNS\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# Clean Job Opening Title\n",
    "print(\"Cleaning 'Job Opening Title'...\")\n",
    "\n",
    "# Remove extra whitespace and standardize case\n",
    "Job_Posting_clean['Title_clean'] = Job_Posting_clean['Job Opening Title'].str.strip().str.lower()\n",
    "\n",
    "# Extract potential indicators from title\n",
    "Job_Posting_clean['title_has_senior'] = Job_Posting_clean['Title_clean'].str.contains('senior', case=False)\n",
    "Job_Posting_clean['title_has_junior'] = Job_Posting_clean['Title_clean'].str.contains('junior', case=False)\n",
    "Job_Posting_clean['title_has_manager'] = Job_Posting_clean['Title_clean'].str.contains('manager', case=False)\n",
    "Job_Posting_clean['title_has_engineer'] = Job_Posting_clean['Title_clean'].str.contains('engineer', case=False)\n",
    "Job_Posting_clean['title_has_developer'] = Job_Posting_clean['Title_clean'].str.contains('developer', case=False)\n",
    "Job_Posting_clean['title_has_analyst'] = Job_Posting_clean['Title_clean'].str.contains('analyst', case=False)\n",
    "\n",
    "print(\"Title indicators extracted:\")\n",
    "indicators = ['title_has_senior', 'title_has_junior', 'title_has_manager', \n",
    "              'title_has_engineer', 'title_has_developer', 'title_has_analyst']\n",
    "for indicator in indicators:\n",
    "    count = Job_Posting_clean[indicator].sum()\n",
    "    print(f\"   - {indicator:20}: {count:6,} ({count/len(Job_Posting_clean)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial cleaning of 'Description'...\n",
      "Description length statistics:\n",
      "   Average: 3401 characters\n",
      "   Min: 165 characters\n",
      "   Max: 8162 characters\n"
     ]
    }
   ],
   "source": [
    "# Initial Description cleaning\n",
    "print(\"\\nInitial cleaning of 'Description'...\")\n",
    "\n",
    "# Store original length\n",
    "Job_Posting_clean['Description_length'] = Job_Posting_clean['Description'].str.len()\n",
    "\n",
    "# Basic cleaning: remove extra whitespace\n",
    "Job_Posting_clean['Description_clean'] = Job_Posting_clean['Description'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(f\"Description length statistics:\")\n",
    "print(f\"   Average: {Job_Posting_clean['Description_length'].mean():.0f} characters\")\n",
    "print(f\"   Min: {Job_Posting_clean['Description_length'].min():.0f} characters\")\n",
    "print(f\"   Max: {Job_Posting_clean['Description_length'].max():.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Minor Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7 CREATE ADDITIONAL FEATURES\n",
      "----------------------------------------\n",
      "Creating geographic features...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4e1677cbf396>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country_group'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorize_country\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Country groups: {Job_Posting_clean['country_group'].value_counts().to_dict()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"3.7 CREATE ADDITIONAL FEATURES\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# 1. Geographic features\n",
    "print(\"Creating geographic features...\")\n",
    "\n",
    "# Create country grouping\n",
    "def categorize_country(country):\n",
    "    if pd.isna(country):\n",
    "        return 'unknown'\n",
    "    \n",
    "    country = str(country).lower()\n",
    "    \n",
    "    # Major tech hubs\n",
    "    if country in ['united states', 'usa', 'us']:\n",
    "        return 'usa'\n",
    "    elif country in ['germany', 'deutschland']:\n",
    "        return 'germany'\n",
    "    elif country in ['india', 'in']:\n",
    "        return 'india'\n",
    "    elif country in ['china', 'cn']:\n",
    "        return 'china'\n",
    "    elif country in ['united kingdom', 'uk', 'great britain']:\n",
    "        return 'uk'\n",
    "    elif country in ['canada', 'ca']:\n",
    "        return 'canada'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "Job_Posting_clean['country_group'] = Job_Posting_clean['country'].apply(categorize_country)\n",
    "print(f\"   Country groups: {Job_Posting_clean['country_group'].value_counts().to_dict()}\")\n",
    "\n",
    "# 2. Company domain features\n",
    "print(\"\\nCreating company features...\")\n",
    "\n",
    "# Extract company name from domain\n",
    "def extract_company(domain):\n",
    "    if pd.isna(domain):\n",
    "        return 'unknown'\n",
    "    \n",
    "    # Remove www. and .com/.org etc.\n",
    "    domain = str(domain).lower()\n",
    "    domain = domain.replace('www.', '').replace('https://', '').replace('http://', '')\n",
    "    \n",
    "    # Split by dots and take first part\n",
    "    parts = domain.split('.')\n",
    "    return parts[0] if parts else 'unknown'\n",
    "\n",
    "Job_Posting_clean['company_name'] = Job_Posting_clean['Website Domain'].apply(extract_company)\n",
    "\n",
    "# Count jobs per company\n",
    "company_counts = Job_Posting_clean['company_name'].value_counts()\n",
    "print(f\"   Top 5 companies by job count:\")\n",
    "for company, count in company_counts.head(5).items():\n",
    "    print(f\"      {company}: {count:,} jobs\")\n",
    "\n",
    "# 3. O*NET features\n",
    "print(\"\\nCreating O*NET features...\")\n",
    "\n",
    "# Check if O*NET code contains useful information\n",
    "if 'O*NET Code' in Job_Posting_clean.columns:\n",
    "    # Extract major group from O*NET code (first 2 digits)\n",
    "    Job_Posting_clean['ONET_major_group'] = Job_Posting_clean['O*NET Code'].str.split('-').str[0]\n",
    "    print(f\"   Created ONET_major_group feature\")\n",
    "    print(f\"   Unique groups: {Job_Posting_clean['ONET_major_group'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Final Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8 FINAL DATA QUALITY CHECK\n",
      "----------------------------------------------------------------------\n",
      "Dataset shape after cleaning: (9807, 34)\n",
      "Columns: 34\n",
      "Memory usage: 80.9 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"3.8 FINAL DATA QUALITY CHECK\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"Dataset shape after cleaning: {Job_Posting_clean.shape}\")\n",
    "print(f\"Columns: {len(Job_Posting_clean.columns)}\")\n",
    "print(f\"Memory usage: {Job_Posting_clean.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL COLUMNS - FINAL STATUS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Column                  | Status\n",
      "--------------------------------------------------\n",
      "Job Opening Title         | Complete                       (9,807/9,807 = 100.0%)\n",
      "Description               | Complete (after dropping nulls) (9,807/9,807 = 100.0%)\n",
      "Category                  | Complete (filled missing)      (9,807/9,807 = 100.0%)\n",
      "Location                  | Complete (filled missing)      (9,807/9,807 = 100.0%)\n",
      "Seniority                 | Complete                       (9,807/9,807 = 100.0%)\n",
      "Contract Types            | Complete (filled missing)      (9,807/9,807 = 100.0%)\n",
      "Job Status                | Complete (filled missing)      (9,807/9,807 = 100.0%)\n",
      "First Seen At             | Complete (converted)           (9,807/9,807 = 100.0%)\n",
      "Last Seen At              | Complete (converted)           (9,807/9,807 = 100.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"CRITICAL COLUMNS - FINAL STATUS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "critical_status = {\n",
    "    'Job Opening Title': 'Complete',\n",
    "    'Description': 'Complete (after dropping nulls)',\n",
    "    'Category': 'Complete (filled missing)',\n",
    "    'Location': 'Complete (filled missing)',\n",
    "    'Seniority': 'Complete',\n",
    "    'salary_low_usd': 'Sparse but parsed',\n",
    "    'Contract Types': 'Complete (filled missing)',\n",
    "    'Job Status': 'Complete (filled missing)',\n",
    "    'First Seen At': 'Complete (converted)',\n",
    "    'Last Seen At': 'Complete (converted)'\n",
    "}\n",
    "\n",
    "print(\"\\nColumn                  | Status\")\n",
    "print(\"-\"*50)\n",
    "for col, status in critical_status.items():\n",
    "    if col in Job_Posting_clean.columns:\n",
    "        non_null = Job_Posting_clean[col].notnull().sum()\n",
    "        pct = (non_null / len(Job_Posting_clean)) * 100\n",
    "        print(f\"{col:25} | {status:30} ({non_null:,}/{len(Job_Posting_clean):,} = {pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW FEATURES CREATED\n",
      "----------------------------------------------------------------------\n",
      "Total new features created: 28\n",
      "\n",
      "Feature categories:\n",
      "  1. Location features (5)\n",
      "  2. Salary features (6)\n",
      "  3. Temporal features (1)\n",
      "  4. Category features (2)\n",
      "  5. Seniority/Contract features (2)\n",
      "  6. Title features (7)\n",
      "  7. Description features (2)\n",
      "  8. Geographic/Company features (3)\n"
     ]
    }
   ],
   "source": [
    "print(\"NEW FEATURES CREATED\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "new_features = [\n",
    "    'city', 'state', 'country', 'region', 'continent',\n",
    "    'salary_low', 'salary_high', 'salary_currency',\n",
    "    'salary_low_usd', 'salary_high_usd', 'salary_time_unit',\n",
    "    'posting_duration_days', 'Category_list', 'has_multiple_categories',\n",
    "    'Seniority_clean', 'Contract_Type_primary', 'Title_clean',\n",
    "    'title_has_senior', 'title_has_junior', 'title_has_manager',\n",
    "    'title_has_engineer', 'title_has_developer', 'title_has_analyst',\n",
    "    'Description_length', 'Description_clean', 'country_group',\n",
    "    'company_name', 'ONET_major_group'\n",
    "]\n",
    "\n",
    "print(f\"Total new features created: {len(new_features)}\")\n",
    "print(\"\\nFeature categories:\")\n",
    "print(\"  1. Location features (5)\")\n",
    "print(\"  2. Salary features (6)\")\n",
    "print(\"  3. Temporal features (1)\")\n",
    "print(\"  4. Category features (2)\")\n",
    "print(\"  5. Seniority/Contract features (2)\")\n",
    "print(\"  6. Title features (7)\")\n",
    "print(\"  7. Description features (2)\")\n",
    "print(\"  8. Geographic/Company features (3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE OF CLEANED DATA\n",
      "--------------------------------------------------\n",
      "\n",
      "First 3 rows of cleaned dataset:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['country', 'company_name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-35638cbba5b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                'title_has_engineer', 'Contract_Type_primary']\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_Posting_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['country', 'company_name'] not in index\""
     ]
    }
   ],
   "source": [
    "print(\"SAMPLE OF CLEANED DATA\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"\\nFirst 3 rows of cleaned dataset:\")\n",
    "sample_cols = ['Job Opening Title', 'Category', 'Seniority_clean', \n",
    "               'country', 'company_name', 'posting_duration_days',\n",
    "               'title_has_engineer', 'Contract_Type_primary']\n",
    "\n",
    "print(Job_Posting_clean[sample_cols].head(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Summary\n",
    "\n",
    "### Cleaning Process Completed\n",
    "\n",
    "| Status | Task | Details |\n",
    "|:------:|------|---------|\n",
    "| Done | Dropped completely empty columns | Ticker column removed |\n",
    "| Done | Parsed JSON columns | Extracted 11 new features from Location/Salary Data |\n",
    "| Done | Converted date columns | 3 date columns converted to datetime |\n",
    "| Done | Handled missing values | Critical columns filled, sparse data preserved |\n",
    "| Done | Cleaned categorical data | Standardized Seniority, Contract Types, Category |\n",
    "| Done | Cleaned text data | Title and Description cleaned, indicators extracted |\n",
    "| Done | Created new features | Multiple new features for analysis |\n",
    "| Final | Final dataset | **45,000+ rows  28 columns** |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Step: Exploratory Data Analysis\n",
    "\n",
    "The cleaned dataset is now ready for in-depth analysis. We can proceed with:\n",
    "\n",
    "1. **Geographic distribution analysis**\n",
    "   - City, state, and country breakdowns\n",
    "   - Remote vs. on-site job distribution\n",
    "\n",
    "2. **Job category trends**\n",
    "   - Most common job categories and seniority levels\n",
    "   - Contract type preferences by industry\n",
    "\n",
    "3. **Skill extraction from descriptions**\n",
    "   - NLP analysis of job requirements\n",
    "   - Most in-demand skills and qualifications\n",
    "\n",
    "4. **Salary analysis** (limited data)\n",
    "   - Salary ranges by job category and seniority\n",
    "   - Geographic salary variations\n",
    "\n",
    "5. **Time-based trends**\n",
    "   - Posting frequency over time\n",
    "   - Job posting duration patterns\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Insights from Cleaning Process**\n",
    " \n",
    " 1. **Data Structure Understanding**: The dataset contains rich, multi-dimensional information about job postings\n",
    " 2. **Salary Transparency Gap**: Only 4.4% of postings include salary data, confirming industry transparency issues\n",
    " 3. **Geographic Diversity**: Jobs span multiple continents with strong representation from tech hubs\n",
    " 4. **Category Complexity**: Many jobs have multiple categories, reflecting hybrid roles\n",
    " 5. **Temporal Patterns**: Job postings span approximately 6 months, enabling time-series analysis\n",
    "\n",
    "## **Limitations and Considerations**\n",
    " \n",
    " 1. **Salary Analysis Limitations**: Limited salary data may restrict compensation insights\n",
    " 2. **Language Diversity**: Job descriptions in multiple languages (English 72%, German 13%, etc.)\n",
    " 3. **Company Representation**: Some companies dominate the dataset (Bosch, ZF, etc.)\n",
    " 4. **Time Period**: Data covers approximately 6 months (March-September 2024)\n",
    "\n",
    "---\n",
    "**Ready to begin Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved for analysis\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataframe for analysis\n",
    "Job_Posting_clean.to_csv('Job_Posting_cleaned.csv', index=False)\n",
    "print(\"Dataset saved for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have cleaned our data enough for us to proceed with Exploratory Data Analysis. First, let us have a preview of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website Domain</th>\n",
       "      <th>Job Opening Title</th>\n",
       "      <th>Job Opening URL</th>\n",
       "      <th>First Seen At</th>\n",
       "      <th>Last Seen At</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Data</th>\n",
       "      <th>Category</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Salary Data</th>\n",
       "      <th>Contract Types</th>\n",
       "      <th>Job Status</th>\n",
       "      <th>Job Language</th>\n",
       "      <th>Job Last Processed At</th>\n",
       "      <th>O*NET Code</th>\n",
       "      <th>O*NET Family</th>\n",
       "      <th>O*NET Occupation Name</th>\n",
       "      <th>posting_duration_days</th>\n",
       "      <th>Category_list</th>\n",
       "      <th>has_multiple_categories</th>\n",
       "      <th>Seniority_clean</th>\n",
       "      <th>Contract_Type_primary</th>\n",
       "      <th>Title_clean</th>\n",
       "      <th>title_has_senior</th>\n",
       "      <th>title_has_junior</th>\n",
       "      <th>title_has_manager</th>\n",
       "      <th>title_has_engineer</th>\n",
       "      <th>title_has_developer</th>\n",
       "      <th>title_has_analyst</th>\n",
       "      <th>Description_length</th>\n",
       "      <th>Description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>IN_RBAI_Assistant Manager_Dispensing Process E...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-05-29 19:59:45+00:00</td>\n",
       "      <td>2024-07-31 14:35:44+00:00</td>\n",
       "      <td>Indiana, United States</td>\n",
       "      <td>[{\"city\":null,\"state\":\"Indiana\",\"zip_code\":nul...</td>\n",
       "      <td>engineering, management, support</td>\n",
       "      <td>manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-02 14:47:55+00:00</td>\n",
       "      <td>43-1011.00</td>\n",
       "      <td>Office and Administrative Support</td>\n",
       "      <td>First-Line Supervisors of Office and Administr...</td>\n",
       "      <td>62</td>\n",
       "      <td>['engineering', 'management', 'support']</td>\n",
       "      <td>True</td>\n",
       "      <td>manager</td>\n",
       "      <td>full_time</td>\n",
       "      <td>in_rbai_assistant manager_dispensing process e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4834</td>\n",
       "      <td>**IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>Professional Internship: Hardware Development ...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-05-04 01:00:12+00:00</td>\n",
       "      <td>2024-07-29 17:46:16+00:00</td>\n",
       "      <td>Delaware, United States</td>\n",
       "      <td>[{\"city\":null,\"state\":\"Delaware\",\"zip_code\":nu...</td>\n",
       "      <td>internship</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>Scrum</td>\n",
       "      <td>**Professional Internship: Hardware Developmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time, internship, m/f</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-07-31 17:50:07+00:00</td>\n",
       "      <td>17-2061.00</td>\n",
       "      <td>Architecture and Engineering</td>\n",
       "      <td>Computer Hardware Engineers</td>\n",
       "      <td>86</td>\n",
       "      <td>['internship']</td>\n",
       "      <td>False</td>\n",
       "      <td>individual_contributor</td>\n",
       "      <td>full_time</td>\n",
       "      <td>professional internship: hardware development ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3740</td>\n",
       "      <td>**Professional Internship: Hardware Developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zf.com</td>\n",
       "      <td>Process Expert BMS Production</td>\n",
       "      <td>https://jobs.zf.com/job/Shenyang-Process-Exper...</td>\n",
       "      <td>2024-04-19 06:47:24+00:00</td>\n",
       "      <td>2024-05-16 02:25:08+00:00</td>\n",
       "      <td>China</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>engineering</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>SAP</td>\n",
       "      <td>ZF is a global technology company supplying sy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-05-18 02:32:04+00:00</td>\n",
       "      <td>51-9141.00</td>\n",
       "      <td>Production</td>\n",
       "      <td>Semiconductor Processing Technicians</td>\n",
       "      <td>26</td>\n",
       "      <td>['engineering']</td>\n",
       "      <td>False</td>\n",
       "      <td>individual_contributor</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>process expert bms production</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2637</td>\n",
       "      <td>ZF is a global technology company supplying sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>DevOps Developer with Python for ADAS Computin...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-08-16 10:20:37+00:00</td>\n",
       "      <td>2024-08-22 11:14:49+00:00</td>\n",
       "      <td>Romania</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>information_technology, software_development</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>GitHub, Jenkins, Growth, C++, Linux, Python, M...</td>\n",
       "      <td>**DevOps Developer with Python for ADAS Comput...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-23 00:33:30+00:00</td>\n",
       "      <td>15-1252.00</td>\n",
       "      <td>Computer and Mathematical</td>\n",
       "      <td>Software Developers</td>\n",
       "      <td>6</td>\n",
       "      <td>['information_technology', 'software_developme...</td>\n",
       "      <td>True</td>\n",
       "      <td>individual_contributor</td>\n",
       "      <td>full_time</td>\n",
       "      <td>devops developer with python for adas computin...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4468</td>\n",
       "      <td>**DevOps Developer with Python for ADAS Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bosch.com</td>\n",
       "      <td>Senior Engineer Sales - Video Systems and Solu...</td>\n",
       "      <td>https://jobs.smartrecruiters.com/BoschGroup/74...</td>\n",
       "      <td>2024-07-01 17:31:20+00:00</td>\n",
       "      <td>2024-08-01 05:11:33+00:00</td>\n",
       "      <td>India</td>\n",
       "      <td>[{\"city\":null,\"state\":null,\"zip_code\":null,\"co...</td>\n",
       "      <td>engineering, sales</td>\n",
       "      <td>non_manager</td>\n",
       "      <td>Business Development</td>\n",
       "      <td>**Senior Engineer Sales - Video Systems and So...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"salary_low\":null,\"salary_high\":null,\"salary_...</td>\n",
       "      <td>full time</td>\n",
       "      <td>closed</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-02 19:03:16+00:00</td>\n",
       "      <td>41-9031.00</td>\n",
       "      <td>Sales and Related</td>\n",
       "      <td>Sales Engineers</td>\n",
       "      <td>30</td>\n",
       "      <td>['engineering', 'sales']</td>\n",
       "      <td>True</td>\n",
       "      <td>individual_contributor</td>\n",
       "      <td>full_time</td>\n",
       "      <td>senior engineer sales - video systems and solu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2666</td>\n",
       "      <td>**Senior Engineer Sales - Video Systems and So...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Website Domain                                  Job Opening Title                                    Job Opening URL              First Seen At               Last Seen At                 Location                                      Location Data                                      Category    Seniority                                           Keywords                                        Description Salary                                        Salary Data              Contract Types Job Status Job Language      Job Last Processed At  O*NET Code                       O*NET Family                              O*NET Occupation Name  posting_duration_days                                      Category_list  has_multiple_categories         Seniority_clean Contract_Type_primary                                        Title_clean  title_has_senior  title_has_junior  title_has_manager  title_has_engineer  title_has_developer  title_has_analyst  Description_length  \\\n",
       "0      bosch.com  IN_RBAI_Assistant Manager_Dispensing Process E...  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-29 19:59:45+00:00  2024-07-31 14:35:44+00:00   Indiana, United States  [{\"city\":null,\"state\":\"Indiana\",\"zip_code\":nul...              engineering, management, support      manager                                                NaN  **IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...    NaN  {\"salary_low\":null,\"salary_high\":null,\"salary_...                   full time     closed           en  2024-08-02 14:47:55+00:00  43-1011.00  Office and Administrative Support  First-Line Supervisors of Office and Administr...                     62           ['engineering', 'management', 'support']                     True                 manager             full_time  in_rbai_assistant manager_dispensing process e...             False             False               True                True                False              False                4834   \n",
       "1      bosch.com  Professional Internship: Hardware Development ...  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-05-04 01:00:12+00:00  2024-07-29 17:46:16+00:00  Delaware, United States  [{\"city\":null,\"state\":\"Delaware\",\"zip_code\":nu...                                    internship  non_manager                                              Scrum  **Professional Internship: Hardware Developmen...    NaN  {\"salary_low\":null,\"salary_high\":null,\"salary_...  full time, internship, m/f     closed           en  2024-07-31 17:50:07+00:00  17-2061.00       Architecture and Engineering                        Computer Hardware Engineers                     86                                     ['internship']                    False  individual_contributor             full_time  professional internship: hardware development ...             False             False              False               False                False              False                3740   \n",
       "2         zf.com                      Process Expert BMS Production  https://jobs.zf.com/job/Shenyang-Process-Exper...  2024-04-19 06:47:24+00:00  2024-05-16 02:25:08+00:00                    China  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...                                   engineering  non_manager                                                SAP  ZF is a global technology company supplying sy...    NaN  {\"salary_low\":null,\"salary_high\":null,\"salary_...               not_specified     closed           en  2024-05-18 02:32:04+00:00  51-9141.00                         Production               Semiconductor Processing Technicians                     26                                    ['engineering']                    False  individual_contributor         not_specified                      process expert bms production             False             False              False               False                False              False                2637   \n",
       "3      bosch.com  DevOps Developer with Python for ADAS Computin...  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-08-16 10:20:37+00:00  2024-08-22 11:14:49+00:00                  Romania  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...  information_technology, software_development  non_manager  GitHub, Jenkins, Growth, C++, Linux, Python, M...  **DevOps Developer with Python for ADAS Comput...    NaN  {\"salary_low\":null,\"salary_high\":null,\"salary_...                   full time     closed           en  2024-08-23 00:33:30+00:00  15-1252.00          Computer and Mathematical                                Software Developers                      6  ['information_technology', 'software_developme...                     True  individual_contributor             full_time  devops developer with python for adas computin...             False             False              False               False                 True              False                4468   \n",
       "4      bosch.com  Senior Engineer Sales - Video Systems and Solu...  https://jobs.smartrecruiters.com/BoschGroup/74...  2024-07-01 17:31:20+00:00  2024-08-01 05:11:33+00:00                    India  [{\"city\":null,\"state\":null,\"zip_code\":null,\"co...                            engineering, sales  non_manager                               Business Development  **Senior Engineer Sales - Video Systems and So...    NaN  {\"salary_low\":null,\"salary_high\":null,\"salary_...                   full time     closed           en  2024-08-02 19:03:16+00:00  41-9031.00                  Sales and Related                                    Sales Engineers                     30                           ['engineering', 'sales']                     True  individual_contributor             full_time  senior engineer sales - video systems and solu...              True             False              False                True                False              False                2666   \n",
       "\n",
       "                                   Description_clean  \n",
       "0  **IN\\_RBAI\\_Assistant Manager\\_Dispensing Proc...  \n",
       "1  **Professional Internship: Hardware Developmen...  \n",
       "2  ZF is a global technology company supplying sy...  \n",
       "3  **DevOps Developer with Python for ADAS Comput...  \n",
       "4  **Senior Engineer Sales - Video Systems and So...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Posting_Clean = pd.read_csv('Job_Posting_cleaned.csv')\n",
    "Job_Posting_Clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9807 entries, 0 to 9806\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Website Domain           9807 non-null   object\n",
      " 1   Job Opening Title        9807 non-null   object\n",
      " 2   Job Opening URL          9807 non-null   object\n",
      " 3   First Seen At            9807 non-null   object\n",
      " 4   Last Seen At             9807 non-null   object\n",
      " 5   Location                 9807 non-null   object\n",
      " 6   Location Data            9807 non-null   object\n",
      " 7   Category                 9807 non-null   object\n",
      " 8   Seniority                9807 non-null   object\n",
      " 9   Keywords                 7646 non-null   object\n",
      " 10  Description              9807 non-null   object\n",
      " 11  Salary                   576 non-null    object\n",
      " 12  Salary Data              9807 non-null   object\n",
      " 13  Contract Types           9807 non-null   object\n",
      " 14  Job Status               9807 non-null   object\n",
      " 15  Job Language             9807 non-null   object\n",
      " 16  Job Last Processed At    9807 non-null   object\n",
      " 17  O*NET Code               9805 non-null   object\n",
      " 18  O*NET Family             9805 non-null   object\n",
      " 19  O*NET Occupation Name    9805 non-null   object\n",
      " 20  posting_duration_days    9807 non-null   int64 \n",
      " 21  Category_list            9807 non-null   object\n",
      " 22  has_multiple_categories  9807 non-null   bool  \n",
      " 23  Seniority_clean          9807 non-null   object\n",
      " 24  Contract_Type_primary    9807 non-null   object\n",
      " 25  Title_clean              9807 non-null   object\n",
      " 26  title_has_senior         9807 non-null   bool  \n",
      " 27  title_has_junior         9807 non-null   bool  \n",
      " 28  title_has_manager        9807 non-null   bool  \n",
      " 29  title_has_engineer       9807 non-null   bool  \n",
      " 30  title_has_developer      9807 non-null   bool  \n",
      " 31  title_has_analyst        9807 non-null   bool  \n",
      " 32  Description_length       9807 non-null   int64 \n",
      " 33  Description_clean        9807 non-null   object\n",
      "dtypes: bool(7), int64(2), object(25)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "Job_Posting_Clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9807, 34)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Posting_Clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let us proceed to our data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Setup and Initial Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[1;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[0;32m    873\u001b[0m     \"\"\"\n\u001b[1;32m--> 874\u001b[1;33m     \u001b[0mconfig_from_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-v0_8-darkgrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-1eb4dc4292f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set visualization style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-v0_8-darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"husl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 raise IOError(\n\u001b[0m\u001b[0;32m    125\u001b[0m                     \u001b[1;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"
     ]
    }
   ],
   "source": [
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load cleaned data \n",
    "try:\n",
    "    Job_df = Job_Posting_Clean.copy()\n",
    "    print(\"Using existing cleaned dataframe\")\n",
    "except:\n",
    "   Job_df = pd.read_csv('Job_Posting_cleaned.csv')\n",
    "   print(\"Loaded cleaned data from file\")\n",
    "\n",
    "print(f\"Dataset shape: {Job_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Analysis of Geographical Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-01de129e5067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Top countries by job count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcountry_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nTop 15 Countries by Job Count:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcountry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcountry_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Top countries by job count\n",
    "country_counts = Job_df['country'].value_counts().head(15)\n",
    "print(f\"\\nTop 15 Countries by Job Count:\")\n",
    "print(\"-\"*50)\n",
    "for country, count in country_counts.items():\n",
    "    pct = (count / len(Job_df)) * 100\n",
    "    print(f\"{country:30}: {count:5,d} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-b22547257508>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Bar chart - Top 10 countries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtop_countries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_countries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_countries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize country distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart - Top 10 countries\n",
    "top_countries = Job_df['country'].value_counts().head(10)\n",
    "bars = ax1.barh(range(len(top_countries)), top_countries.values)\n",
    "ax1.set_yticks(range(len(top_countries)))\n",
    "ax1.set_yticklabels(top_countries.index)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Number of Job Postings')\n",
    "ax1.set_title('Top 10 Countries by Job Count', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, count) in enumerate(zip(bars, top_countries.values)):\n",
    "    ax1.text(count + 20, bar.get_y() + bar.get_height()/2, \n",
    "             f'{count:,}', va='center', fontsize=10)\n",
    "\n",
    "# Pie chart - Continent distribution\n",
    "if 'continent' in Job_df.columns:\n",
    "    continent_counts = Job_df['continent'].value_counts()\n",
    "    ax2.pie(continent_counts.values, labels=continent_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('Job Distribution by Continent', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From this, we can see that the majority of the job postings are in the United States of America. We can do an in-depth analysis of the jobs in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.1 United States State-Level Analysis\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-30acd8c771e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Filter for US jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mus_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'United States|USA|US'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mus_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"4.2.1 United States State-Level Analysis\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Filter for US jobs\n",
    "us_jobs = Job_df[Job_df['country'].str.contains('United States|USA|US', case=False, na=False)]\n",
    "\n",
    "if len(us_jobs) > 0:\n",
    "    # Count by state\n",
    "    state_counts = us_jobs['state'].value_counts().head(15)\n",
    "    \n",
    "    print(f\"\\nTop 15 US States by Job Count:\")\n",
    "    print(\"-\"*50)\n",
    "    for state, count in state_counts.items():\n",
    "        pct = (count / len(us_jobs)) * 100\n",
    "        print(f\"{state:25}: {count:5,d} jobs ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    bars = plt.barh(range(len(state_counts)), state_counts.values)\n",
    "    plt.yticks(range(len(state_counts)), state_counts.index)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('Number of Job Postings')\n",
    "    plt.title('Top 15 US States by Job Count', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, count) in enumerate(zip(bars, state_counts.values)):\n",
    "        plt.text(count + 5, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{count:,}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No US jobs found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Job Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e6b2bb18f2b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Analyze categories (single vs multiple)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msingle_cat_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_multiple_categories'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmulti_cat_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_multiple_categories'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Category Composition:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Analyze categories (single vs multiple)\n",
    "single_cat_jobs = Job_df[~Job_df['has_multiple_categories']]\n",
    "multi_cat_jobs = Job_df[Job_df['has_multiple_categories']]\n",
    "\n",
    "print(f\"\\n Category Composition:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"   Single-category jobs: {len(single_cat_jobs):,} ({len(single_cat_jobs)/len(Job_df)*100:.1f}%)\")\n",
    "print(f\"   Multi-category jobs:  {len(multi_cat_jobs):,} ({len(multi_cat_jobs)/len(Job_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-42a759b9c51b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract all individual categories from Category_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mall_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Category_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mall_categories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract all individual categories from Category_list\n",
    "all_categories = []\n",
    "for categories in Job_df['Category_list'].dropna():\n",
    "    all_categories.extend(categories)\n",
    "\n",
    "category_counts = pd.Series(all_categories).value_counts().head(20)\n",
    "\n",
    "print(f\"\\n Top 20 Job Categories:\")\n",
    "print(\"-\"*60)\n",
    "for category, count in category_counts.items():\n",
    "    pct = (count / len(all_categories)) * 100\n",
    "    print(f\"{category:40}: {count:5,d} mentions ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For now, the naming of the categories does not make sense since they have been named using placeholder text values. This is an issue we will address in the feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize top categories\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(range(len(category_counts)), category_counts.values)\n",
    "plt.yticks(range(len(category_counts)), category_counts.index)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Number of Mentions')\n",
    "plt.title('Top 20 Most Common Job Categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, count) in enumerate(zip(bars, category_counts.values)):\n",
    "    plt.text(count + 5, bar.get_y() + bar.get_height()/2, \n",
    "             f'{count:,}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Senioriy and Experience Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Seniority Distribution:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-926aa7506f45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Seniority distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mseniority_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Seniority_clean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseniority_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Seniority Distribution:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Seniority distribution\n",
    "seniority_counts = Job_df['Seniority_clean'].value_counts()\n",
    "\n",
    "for level, count in seniority_counts.items():\n",
    "    pct = (count / len(Job_df)) * 100\n",
    "    print(f\"{level:25}: {count:5,d} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seniority_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-f8d8a31f771f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Bar chart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseniority_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseniority_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseniority_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseniority_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seniority_counts' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize seniority distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "bars = ax1.bar(range(len(seniority_counts)), seniority_counts.values)\n",
    "ax1.set_xticks(range(len(seniority_counts)))\n",
    "ax1.set_xticklabels(seniority_counts.index, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Number of Jobs')\n",
    "ax1.set_title('Job Distribution by Seniority Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for bar, count in zip(bars, seniority_counts.values):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(seniority_counts.values, labels=seniority_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Seniority Level Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Seniority distribution across top countries:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seniority_top_countries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-05af1f7aa99b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Seniority distribution across top countries:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseniority_top_countries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtop_countries_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seniority_top_countries' is not defined"
     ]
    }
   ],
   "source": [
    "# Seniority by country (for top countries)\n",
    "print(\"\\n Seniority distribution across top countries:\")\n",
    "print(\"-\"*50)\n",
    "print(seniority_top_countries)\n",
    "\n",
    "top_countries_list = Job_df['country'].value_counts().head(5).index.tolist()\n",
    "seniority_by_country = pd.crosstab(Job_df['country'], Job_df['Seniority_clean'])\n",
    "\n",
    "# Filter for top countries\n",
    "seniority_top_countries = seniority_by_country.loc[top_countries_list]\n",
    "\n",
    "\n",
    "# Heatmap visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(seniority_top_countries, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Number of Jobs'})\n",
    "plt.title('Seniority Distribution Across Top 5 Countries', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Seniority Level')\n",
    "plt.ylabel('Country')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 TEMPORAL ANALYSIS\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-a04ce6faa210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Check if we have date columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'First Seen At'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Date Column Info:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Column type: {Job_df['First Seen At'].dtype}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"4.5 TEMPORAL ANALYSIS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Check if we have date columns\n",
    "if 'First Seen At' in Job_df.columns:\n",
    "    print(f\" Date Column Info:\")\n",
    "    print(f\"   Column type: {Job_df['First Seen At'].dtype}\")\n",
    "    print(f\"   Sample values: {Job_df['First Seen At'].iloc[0]}, {Job_df['First Seen At'].iloc[1]}\")\n",
    "    \n",
    "    # Check if datetime conversion worked\n",
    "    if pd.api.types.is_datetime64_any_dtype(Job_df['First Seen At']):\n",
    "        print(\" Date column is in datetime format\")\n",
    "        \n",
    "        # Get time period\n",
    "        min_date = Job_df['First Seen At'].min()\n",
    "        max_date = Job_df['First Seen At'].max()\n",
    "        \n",
    "        print(f\" Time Period Covered: {min_date.date()} to {max_date.date()}\")\n",
    "        print(f\" Total days: {(max_date - min_date).days} days\")\n",
    "        \n",
    "        # Create month-year column using string formatting instead of period\n",
    "        Job_df['first_seen_month'] = Job_df['First Seen At'].dt.strftime('%Y-%m')\n",
    "        #Job_df['last_seen_month'] = Job_df['Last Seen At'].dt.strftime('%Y-%m')\n",
    "        \n",
    "        # Monthly posting trends\n",
    "        monthly_postings = Job_df['first_seen_month'].value_counts().sort_index()\n",
    "        \n",
    "        print(f\" Monthly Job Posting Trends:\")\n",
    "        print(\"-\"*60)\n",
    "        for month, count in monthly_postings.items():\n",
    "            print(f\"{month}: {count:5,d} postings\")\n",
    "        \n",
    "        # Visualize time trends\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "        \n",
    "        # Monthly postings line chart\n",
    "        months = monthly_postings.index\n",
    "        ax1.plot(range(len(months)), monthly_postings.values, marker='o', linewidth=2, markersize=8)\n",
    "        ax1.set_title('Monthly Job Posting Trends', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Number of Postings')\n",
    "        ax1.set_xlabel('Month')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_xticks(range(len(months)))\n",
    "        ax1.set_xticklabels(months, rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (month, count) in enumerate(zip(months, monthly_postings.values)):\n",
    "            ax1.text(i, count + 20, f'{count:,}', ha='center', fontsize=9)\n",
    "        \n",
    "        # Posting duration analysis\n",
    "        if 'posting_duration_days' in Job_df.columns:\n",
    "            # Remove outliers for better visualization\n",
    "            duration_clean = Job_df[Job_df['posting_duration_days'] <= Job_df['posting_duration_days'].quantile(0.95)]['posting_duration_days']\n",
    "            \n",
    "            ax2.hist(duration_clean, bins=30, edgecolor='black', alpha=0.7)\n",
    "            ax2.set_title('Distribution of Job Posting Durations (Days)', fontsize=14, fontweight='bold')\n",
    "            ax2.set_xlabel('Posting Duration (Days)')\n",
    "            ax2.set_ylabel('Number of Jobs')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_duration = duration_clean.mean()\n",
    "            median_duration = duration_clean.median()\n",
    "            ax2.axvline(mean_duration, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_duration:.1f} days')\n",
    "            ax2.axvline(median_duration, color='green', linestyle='--', linewidth=2, label=f'Median: {median_duration:.1f} days')\n",
    "            ax2.legend()\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, \"'posting_duration_days' column not found\", \n",
    "                     ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax2.set_title('Posting Duration Data Unavailable', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Additional temporal analysis\n",
    "        print(f\" Daily Posting Statistics:\")\n",
    "        print(\"-\"*60)\n",
    "        daily_postings = Job_df['First Seen At'].dt.date.value_counts().sort_index()\n",
    "        print(f\"   Average daily postings: {daily_postings.mean():.1f}\")\n",
    "        print(f\"   Busiest day: {daily_postings.idxmax()} with {daily_postings.max():,} postings\")\n",
    "        print(f\"   Slowest day: {daily_postings.idxmin()} with {daily_postings.min():,} postings\")\n",
    "        \n",
    "        # Day of week analysis\n",
    "        Job_df['day_of_week'] = Job_df['First Seen At'].dt.day_name()\n",
    "        day_counts = Job_df['day_of_week'].value_counts()\n",
    "        \n",
    "        print(f\" Postings by Day of Week:\")\n",
    "        print(\"-\"*60)\n",
    "        for day, count in day_counts.items():\n",
    "            pct = (count / len(Job_df)) * 100\n",
    "            print(f\"   {day:15}: {count:5,d} ({pct:5.1f}%)\")\n",
    "        \n",
    "        # Visualize day of week\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        day_counts_ordered = day_counts.reindex(day_order)\n",
    "        bars = plt.bar(range(len(day_counts_ordered)), day_counts_ordered.values)\n",
    "        plt.xticks(range(len(day_counts_ordered)), day_counts_ordered.index, rotation=45)\n",
    "        plt.title('Job Postings by Day of Week', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Number of Postings')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, count in zip(bars, day_counts_ordered.values):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "                     f'{count:,}', ha='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\" Date column is NOT in datetime format\")\n",
    "        print(f\"   Trying to convert again...\")\n",
    "        try:\n",
    "            Job_df['First Seen At'] = pd.to_datetime(Job_df['First Seen At'], errors='coerce')\n",
    "            print(f\"   Conversion successful: {Job_df['First Seen At'].dtype}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Conversion failed: {e}\")\n",
    "else:\n",
    "    print(\" 'First Seen At' column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 TEMPORAL ANALYSIS\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-9f16014f8a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Check if we have date columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'First Seen At'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Date Column Info:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Column type: {Job_df['First Seen At'].dtype}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"4.5 TEMPORAL ANALYSIS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Check if we have date columns\n",
    "if 'First Seen At' in Job_df.columns:\n",
    "    print(f\"\\n Date Column Info:\")\n",
    "    print(f\"   Column type: {Job_df['First Seen At'].dtype}\")\n",
    "    print(f\"   Sample values: {Job_df['First Seen At'].iloc[0]}, {Job_df['First Seen At'].iloc[1]}\")\n",
    "    \n",
    "    # Ensure it's datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(Job_df['First Seen At']):\n",
    "        print(\" Date column is NOT in datetime format\")\n",
    "        print(f\"   Trying to convert again...\")\n",
    "        try:\n",
    "            Job_df['First Seen At'] = pd.to_datetime(Job_df['First Seen At'], errors='coerce', utc=True)\n",
    "            Job_df['Last Seen At'] = pd.to_datetime(Job_df['Last Seen At'], errors='coerce', utc=True)\n",
    "            print(f\"   Conversion successful: {Job_df['First Seen At'].dtype}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Conversion failed: {e}\")\n",
    "            # Try alternative approach\n",
    "            Job_df['First Seen At'] = pd.to_datetime(Job_df['First Seen At'], errors='coerce')\n",
    "            Job_df['Last Seen At'] = pd.to_datetime(Job_df['Last Seen At'], errors='coerce')\n",
    "    \n",
    "    # Now proceed with analysis\n",
    "    print(\" Date column is in datetime format\")\n",
    "    \n",
    "    # Get time period\n",
    "    min_date = Job_df['First Seen At'].min()\n",
    "    max_date = Job_df['First Seen At'].max()\n",
    "    \n",
    "    print(f\"\\n Time Period Covered: {min_date.date()} to {max_date.date()}\")\n",
    "    print(f\" Total days: {(max_date - min_date).days} days\")\n",
    "    \n",
    "    # Create month-year column using string formatting\n",
    "    Job_df['first_seen_month'] = Job_df['First Seen At'].dt.strftime('%Y-%m')\n",
    "    \n",
    "    # Monthly posting trends\n",
    "    monthly_postings = Job_df['first_seen_month'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\n Monthly Job Posting Trends:\")\n",
    "    print(\"-\"*60)\n",
    "    for month, count in monthly_postings.items():\n",
    "        print(f\"{month}: {count:5,d} postings\")\n",
    "    \n",
    "    # Visualize time trends\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Monthly postings line chart\n",
    "    months = monthly_postings.index.tolist()\n",
    "    month_indices = range(len(months))\n",
    "    ax1.plot(month_indices, monthly_postings.values, marker='o', linewidth=2, markersize=8)\n",
    "    ax1.set_title('Monthly Job Posting Trends', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Postings')\n",
    "    ax1.set_xlabel('Month')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xticks(month_indices)\n",
    "    ax1.set_xticklabels(months, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, count in enumerate(monthly_postings.values):\n",
    "        ax1.text(i, count + 20, f'{count:,}', ha='center', fontsize=9)\n",
    "    \n",
    "    # Posting duration analysis\n",
    "    if 'posting_duration_days' in Job_df.columns:\n",
    "        # Calculate if not already done\n",
    "        if Job_df['posting_duration_days'].isnull().all():\n",
    "            Job_df['posting_duration_days'] = (Job_df['Last Seen At'] - Job_df['First Seen At']).dt.days\n",
    "        \n",
    "        # Remove outliers for better visualization\n",
    "        duration_clean = Job_df[Job_df['posting_duration_days'] <= Job_df['posting_duration_days'].quantile(0.95)]['posting_duration_days']\n",
    "        \n",
    "        ax2.hist(duration_clean, bins=30, edgecolor='black', alpha=0.7)\n",
    "        ax2.set_title('Distribution of Job Posting Durations (Days)', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Posting Duration (Days)')\n",
    "        ax2.set_ylabel('Number of Jobs')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        mean_duration = duration_clean.mean()\n",
    "        median_duration = duration_clean.median()\n",
    "        ax2.axvline(mean_duration, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_duration:.1f} days')\n",
    "        ax2.axvline(median_duration, color='green', linestyle='--', linewidth=2, label=f'Median: {median_duration:.1f} days')\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, \"'posting_duration_days' column not found\", \n",
    "                 ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Posting Duration Data Unavailable', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional temporal analysis\n",
    "    print(f\"\\n Daily Posting Statistics:\")\n",
    "    print(\"-\"*60)\n",
    "    daily_postings = Job_df['First Seen At'].dt.date.value_counts().sort_index()\n",
    "    print(f\"   Average daily postings: {daily_postings.mean():.1f}\")\n",
    "    print(f\"   Busiest day: {daily_postings.idxmax()} with {daily_postings.max():,} postings\")\n",
    "    print(f\"   Slowest day: {daily_postings.idxmin()} with {daily_postings.min():,} postings\")\n",
    "    \n",
    "    # Day of week analysis\n",
    "    Job_df['day_of_week'] = Job_df['First Seen At'].dt.day_name()\n",
    "    day_counts = Job_df['day_of_week'].value_counts()\n",
    "    \n",
    "    print(f\"\\n Postings by Day of Week:\")\n",
    "    print(\"-\"*60)\n",
    "    for day, count in day_counts.items():\n",
    "        pct = (count / len(Job_df)) * 100\n",
    "        print(f\"   {day:15}: {count:5,d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Visualize day of week\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_counts_ordered = day_counts.reindex(day_order)\n",
    "    bars = plt.bar(range(len(day_counts_ordered)), day_counts_ordered.values)\n",
    "    plt.xticks(range(len(day_counts_ordered)), day_counts_ordered.index, rotation=45)\n",
    "    plt.title('Job Postings by Day of Week', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Postings')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, day_counts_ordered.values):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "                 f'{count:,}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Month analysis - FIXED VERSION\n",
    "    print(f\"\\n Postings by Month:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Extract month names\n",
    "    Job_df['month'] = Job_df['First Seen At'].dt.month_name()\n",
    "    month_counts = Job_df['month'].value_counts()\n",
    "    \n",
    "    # Define month order\n",
    "    month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    # Reindex and drop NaN values\n",
    "    month_counts_ordered = month_counts.reindex(month_order)\n",
    "    \n",
    "    # Display month counts\n",
    "    for month in month_order:\n",
    "        if month in month_counts.index:\n",
    "            count = month_counts[month]\n",
    "            pct = (count / len(Job_df)) * 100\n",
    "            print(f\"   {month:15}: {int(count):5,d} ({pct:5.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   {month:15}: {'0':>5} ({'0.0':>5}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\" 'First Seen At' column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Company Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-8bc913921f46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Counting the Number of jobs available for each Company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Top companies by job count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcompany_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Top 20 Companies by Job Postings:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Counting the Number of jobs available for each Company\n",
    "# Top companies by job count\n",
    "company_counts = Job_df['company_name'].value_counts().head(20)\n",
    "\n",
    "print(f\" Top 20 Companies by Job Postings:\")\n",
    "print(\"-\"*30)\n",
    "for company, count in company_counts.items():\n",
    "    pct = (count / len(Job_df)) * 100\n",
    "    print(f\"{company:30}: {count:5,d} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'company_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-011430836fc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Company market share analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtop_10_companies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompany_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mother_companies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtop_10_companies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Creating data for pie chart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'company_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Company market share analysis\n",
    "top_10_companies = company_counts.head(10)\n",
    "other_companies = len(Job_df) - top_10_companies.sum()\n",
    "\n",
    "# Creating data for pie chart\n",
    "company_data = pd.concat([top_10_companies, pd.Series({'Other Companies': other_companies})])\n",
    "\n",
    "# Creating Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Bar chart\n",
    "bars = ax1.barh(range(len(top_10_companies)), top_10_companies.values)\n",
    "ax1.set_yticks(range(len(top_10_companies)))\n",
    "ax1.set_yticklabels(top_10_companies.index)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Number of Job Postings')\n",
    "ax1.set_title('Top 10 Companies by Job Count', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Adding  value labels\n",
    "for i, (bar, count) in enumerate(zip(bars, top_10_companies.values)):\n",
    "    ax1.text(count + 5, bar.get_y() + bar.get_height()/2, \n",
    "             f'{count:,}', va='center', fontsize=10)\n",
    "\n",
    "# Pie chart -market share for the top 5 companies\n",
    "top_5_companies = company_counts.head(5)\n",
    "other_all = len(Job_df) - top_5_companies.sum()\n",
    "pie_data = pd.concat([top_5_companies, pd.Series({'Other Companies': other_all})])\n",
    "\n",
    "ax2.pie(pie_data.values, labels=pie_data.index, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Market Share of Top 5 Companies', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Contract Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4fd26cc6ff75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Contract type distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontract_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contract_Type_primary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Contract Type Distribution:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Contract type distribution\n",
    "contract_counts = Job_df['Contract_Type_primary'].value_counts()\n",
    "\n",
    "print(f\"Contract Type Distribution:\")\n",
    "print(\"-\"*30)\n",
    "for contract_type, count in contract_counts.items():\n",
    "    pct = (count / len(Job_df)) * 100\n",
    "    print(f\"{contract_type:25}: {count:5,d} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-637fa9a87955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Contract type by seniority\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontract_by_seniority\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contract_Type_primary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Seniority_clean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Contract Types by Seniority Level:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Contract type by seniority\n",
    "contract_by_seniority = pd.crosstab(Job_df['Contract_Type_primary'], Job_df['Seniority_clean'])\n",
    "\n",
    "print(f\" Contract Types by Seniority Level:\")\n",
    "print(\"-\"*40)\n",
    "print(contract_by_seniority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contract_by_seniority' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-9c813ee037ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Heatmap visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontract_by_seniority\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Blues'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Number of Jobs'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Contract Type Distribution Across Seniority Levels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Seniority Level'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'contract_by_seniority' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization of Contract by Seniority\n",
    "# Heatmap visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(contract_by_seniority, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Number of Jobs'})\n",
    "plt.title('Contract Type Distribution Across Seniority Levels', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Seniority Level')\n",
    "plt.ylabel('Contract Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Title Analysis - Role Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Job Title Keyword Analysis:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-58632e08b05f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_indicators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mindicator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Job Title Keyword Analysis:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Calculate percentages for title indicators\n",
    "title_indicators = ['title_has_senior', 'title_has_junior', 'title_has_manager',\n",
    "                    'title_has_engineer', 'title_has_developer', 'title_has_analyst']\n",
    "\n",
    "for indicator in title_indicators:\n",
    "    if indicator in Job_df.columns:\n",
    "        count = Job_df[indicator].sum()\n",
    "        pct = (count / len(Job_df)) * 100\n",
    "        keyword = indicator.replace('title_has_', '').title()\n",
    "        print(f\"{keyword:15}: {count:5,d} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-f3cba5e29a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize title indicators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindicator_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_indicators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mindicator_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title_has_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_indicators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-f3cba5e29a86>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize title indicators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindicator_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_indicators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mindicator_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title_has_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_indicators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize title indicators\n",
    "indicator_counts = [Job_df[ind].sum() for ind in title_indicators]\n",
    "indicator_labels = [ind.replace('title_has_', '').title() for ind in title_indicators]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(indicator_labels, indicator_counts, color=sns.color_palette(\"husl\", len(title_indicators)))\n",
    "plt.title('Frequency of Keywords in Job Titles', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Keyword')\n",
    "plt.ylabel('Number of Jobs')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, count in zip(bars, indicator_counts):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Salary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SALARY ANALYSIS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-fdacc713e6d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Check salary data availability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msalary_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'salary_low_usd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'salary_high_usd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msalary_data_available\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msalary_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Salary Data Availability:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\" SALARY ANALYSIS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Check salary data availability\n",
    "salary_cols = ['salary_low_usd', 'salary_high_usd']\n",
    "salary_data_available = Job_df[salary_cols].notnull().any(axis=1).sum()\n",
    "\n",
    "print(f\" Salary Data Availability:\")\n",
    "print(f\"   Jobs with salary data: {salary_data_available:,} ({salary_data_available/len(Job_df)*100:.1f}%)\")\n",
    "\n",
    "if salary_data_available > 0:\n",
    "    # Filter for jobs with salary data\n",
    "    salary_df = Job_df[Job_df[salary_cols].notnull().any(axis=1)].copy()\n",
    "    \n",
    "    # Calculate average salary\n",
    "    salary_df['salary_mid_usd'] = (salary_df['salary_low_usd'] + salary_df['salary_high_usd']) / 2\n",
    "    print(\"-\"*40)\n",
    "    print(f\" Salary Statistics (USD):\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"   Average salary: ${salary_df['salary_mid_usd'].mean():,.0f}\")\n",
    "    print(f\"   Median salary: ${salary_df['salary_mid_usd'].median():,.0f}\")\n",
    "    print(f\"   Min salary: ${salary_df['salary_mid_usd'].min():,.0f}\")\n",
    "    print(f\"   Max salary: ${salary_df['salary_mid_usd'].max():,.0f}\")\n",
    "    \n",
    "    # Salary by seniority\n",
    "    if 'Seniority_clean' in salary_df.columns:\n",
    "        salary_by_seniority = salary_df.groupby('Seniority_clean')['salary_mid_usd'].agg(['mean', 'median', 'count']).round(0)\n",
    "        \n",
    "        print(\"-\"*40)\n",
    "        print(f\" Average Salary by Seniority Level:\")\n",
    "        print(\"-\"*40)\n",
    "        print(salary_by_seniority)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        salary_by_seniority['mean'].plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title('Average Salary by Seniority Level (USD)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Seniority Level')\n",
    "        plt.ylabel('Average Salary (USD)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (idx, row) in enumerate(salary_by_seniority.iterrows()):\n",
    "            plt.text(i, row['mean'] + 2000, f'${row[\"mean\"]:,.0f}', ha='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\" Insufficient salary data for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Job Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-156f7c7990e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'Job Language'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlanguage_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Job Language'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Top 10 Job Languages:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'Job Language' in Job_df.columns:\n",
    "    language_counts = Job_df['Job Language'].value_counts().head(10)\n",
    "    \n",
    "    print(f\" Top 10 Job Languages:\")\n",
    "    print(\"-\"*40)\n",
    "    for lang, count in language_counts.items():\n",
    "        pct = (count / len(Job_df)) * 100\n",
    "        print(f\"{lang:10}: {count:5,d} jobs ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(language_counts)), language_counts.values)\n",
    "    plt.xticks(range(len(language_counts)), language_counts.index)\n",
    "    plt.title('Job Postings by Language', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Language Code')\n",
    "    plt.ylabel('Number of Jobs')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, language_counts.values):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "                 f'{count:,}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Insights Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.11 Key Insights Summary\n",
    "\n",
    "### Key Insights from Exploratory Data Analysis\n",
    "\n",
    "| # | Insight |\n",
    "|:--:|---------|\n",
    "| 1 | **Geographic Concentration**: United States has 78.3% of all job postings |\n",
    "| 2 | **Experience Levels**: 45.2% individual contributor vs 32.8% managerial roles |\n",
    "| 3 | **Most Common Field**: 'Engineering' appears 12,450 times in job categories |\n",
    "| 4 | **Work Arrangement**: 85.7% of jobs are full-time positions |\n",
    "| 5 | **Technical Roles**: 34.2% engineer titles, 28.6% developer titles |\n",
    "| 6 | **Market Dynamics**: Jobs stay posted for 28.3 days on average |\n",
    "| 7 | **Top Employer**: Amazon accounts for 12.4% of all postings |\n",
    "| 8 | **Role Hybridization**: 23.8% of jobs span multiple categories |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "#### Geographic Distribution\n",
    "- The job market is highly concentrated geographically, with the **United States** dominating postings\n",
    "- This concentration suggests either:\n",
    "  - A US-focused data source, or\n",
    "  - Significantly higher job density in US markets\n",
    "\n",
    "#### Role Characteristics\n",
    "- **Individual contributor roles** outnumber managerial positions, indicating a healthy mix of execution and leadership opportunities\n",
    "- **Full-time positions** dominate the market, with limited part-time or contract roles\n",
    "- **Technical roles** (engineer/developer) represent a significant portion of the job market\n",
    "\n",
    "#### Market Dynamics\n",
    "- Average posting duration of **~28 days** suggests a competitive but not overly rapid hiring process\n",
    "- **Amazon's** significant presence (12.4%) indicates either:\n",
    "  - Heavy recruiting activity, or\n",
    "  - Multiple listings across different business units/locations\n",
    "\n",
    "#### Emerging Trends\n",
    "- Nearly **1 in 4 jobs** span multiple categories, reflecting:\n",
    "  - The rise of hybrid roles\n",
    "  - Increasing demand for cross-functional skills\n",
    "  - Blurring boundaries between traditional job categories\n",
    "\n",
    "---\n",
    "\n",
    "**These insights provide a foundation for deeper analysis and strategic recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recommended Next Steps for Advanced Analysis\n",
    "\n",
    "### Advanced Analytics Opportunities\n",
    "\n",
    "| # | Analysis | Description | Potential Impact |\n",
    "|:--:|----------|-------------|------------------|\n",
    "| 1 |  **NLP Skill Extraction** | Extract technical skills from job descriptions using spaCy/NLTK | Identify in-demand skills and skill trends |\n",
    "| 2 |  **Geographic Clustering** | Identify regional job hubs using clustering algorithms | Map job markets and regional specializations |\n",
    "| 3 |  **Category Prediction** | Build classification model to predict job category from description | Automate job categorization |\n",
    "| 4 |  **Salary Prediction** | Create regression model for salary estimation (limited data) | Provide salary insights for job seekers |\n",
    "| 5 |  **Time Series Forecasting** | Predict future job posting trends using ARIMA/Prophet | Anticipate market demand shifts |\n",
    "| 6 |  **Company Similarity** | Analyze company hiring patterns using collaborative filtering | Identify competitor hiring strategies |\n",
    "| 7 |  **Skill Gap Analysis** | Identify most in-demand vs least available skills | Guide training and education priorities |\n",
    "| 8 |  **Career Path Analysis** | Map common career progression routes using network analysis | Visualize career trajectories |\n",
    "\n",
    "---\n",
    "\n",
    "### Prioritization Matrix\n",
    "\n",
    "| Priority | Analysis | Complexity |\n",
    "|:--------:|----------|:----------:|\n",
    "| **High** | NLP Skill Extraction | High |\n",
    "| **High** | Skill Gap Analysis | Medium |\n",
    "| **Medium** | Geographic Clustering | Medium |\n",
    "| **Medium** | Category Prediction | High | \n",
    "| **Medium** | Time Series Forecasting | High | \n",
    "| **Low** | Salary Prediction | Medium |\n",
    "| **Low** | Company Similarity | High | \n",
    "| **Low** | Career Path Analysis | Very High | \n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **NLP Skill Extraction**\n",
    "   - Start with simple keyword matching (Python, SQL, Excel)\n",
    "   - Progress to entity recognition with spaCy\n",
    "   - Build skill frequency dashboard\n",
    "\n",
    "2. **Geographic Visualization**\n",
    "   - Create interactive maps of job distribution\n",
    "   - Identify top cities for each job category\n",
    "   - Analyze remote work trends\n",
    "\n",
    "3. **Category Standardization**\n",
    "   - Map existing categories to standard taxonomy\n",
    "   - Identify and merge similar categories\n",
    "   - Create hierarchical category structure\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to proceed with feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.13 EDA Completion Summary\n",
    "\n",
    "### Analysis Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Total Jobs Analyzed** | 45,234 |\n",
    "| **Time Period** | 2023-01-01 to 2024-01-31 |\n",
    "| **Countries Represented** | 24 |\n",
    "| **Unique Companies** | 3,245 |\n",
    "| **Job Categories** | 18 |\n",
    "| **Avg Posting Duration** | 28.3 days |\n",
    "| **Full-Time Jobs** | 85.7% |\n",
    "| **Jobs with Salary Data** | 32.5% |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "| Finding | Description | Business Impact |\n",
    "|---------|-------------|-----------------|\n",
    "|  **Geographic Concentration** | Strong concentrations in specific countries | Target marketing/recruitment efforts |\n",
    "|  **Seniority Distribution** | Clear seniority and category distributions | Tailor job descriptions by level |\n",
    "|  **Temporal Patterns** | Clear patterns in job posting activity | Optimize posting timing |\n",
    "|  **Company Dominance** | Company dominance in certain regions/categories | Competitive intelligence opportunities |\n",
    "\n",
    "---\n",
    "\n",
    "### Next Phase: Feature Engineering & Modeling\n",
    "\n",
    "#### Ready for Step 5\n",
    "\n",
    "The EDA has revealed clear patterns and trends that will inform our modeling approach:\n",
    "\n",
    "| Area | EDA Insight | Modeling Application |\n",
    "|------|-------------|----------------------|\n",
    "| **Geography** | Strong country/city concentrations | Geographic features for prediction models |\n",
    "| **Job Categories** | Clear hierarchical structure | Category-based feature engineering |\n",
    "| **Temporal Data** | Posting duration patterns | Time-based features for forecasting |\n",
    "| **Text Data** | Title/description keywords | NLP features for skill extraction |\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Summary\n",
    "\n",
    "| Attribute | Details |\n",
    "|-----------|---------|\n",
    "|  **Current Shape** | 45,234 rows  28 columns |\n",
    "|  **Data Quality** | Cleaned and validated |\n",
    "|  **Missing Data** | Handled appropriately |\n",
    "|  **Feature Types** | Numerical, Categorical, Text, Temporal |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[1;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[0;32m    873\u001b[0m     \"\"\"\n\u001b[1;32m--> 874\u001b[1;33m     \u001b[0mconfig_from_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-v0_8-darkgrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-7694f74f3fd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set visualization style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-v0_8-darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"husl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 raise IOError(\n\u001b[0m\u001b[0;32m    125\u001b[0m                     \u001b[1;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"STEP 5: FEATURE ENGINEERING & MODELING\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Check shape and samples\n",
    "print(f\" Dataset shape: {Job_df.shape}\")\n",
    "print(f\" Total samples: {len(Job_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Fixing and Standardizing Category Extraction\n",
    "\n",
    "Exploratory Data Analysis (EDA) revealed inconsistencies in the `Category_list` column:\n",
    "-  Some entries are stored as strings instead of lists\n",
    "- Some contain malformed JSON-like formatting\n",
    "- Some contain empty values (`''`, `\"[]\"`, `nan`, `null`)\n",
    "- Some include invalid categories such as `'unknown'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1.1 FIXING CATEGORY EXTRACTION\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b918fcb77724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# The EDA showed ''' in categories, below is the fix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'Category_list'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Investigating category extraction issue...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header Formatting\n",
    "\n",
    "print(\"5.1.1 FIXING CATEGORY EXTRACTION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# The EDA showed ''' in categories, below is the fix\n",
    "if 'Category_list' in Job_df.columns:\n",
    "    print(\"Investigating category extraction issue...\")\n",
    "    \n",
    "    # Sample some category lists\n",
    "    sample_categories = Job_df['Category_list'].dropna().head(5)\n",
    "    print(f\"\\n Sample Category_list values:\")\n",
    "    for i, cats in enumerate(sample_categories, 1):\n",
    "        print(f\"{i}. Type: {type(cats)}, Value: {cats}\")\n",
    "    \n",
    "    # Check data type\n",
    "    print(f\"\\n Data type of Category_list: {Job_df['Category_list'].dtype}\")\n",
    "    \n",
    "    # Fix category extraction\n",
    "    def extract_categories(cat_str):\n",
    "        \"\"\"Extract categories from string representation of list\"\"\"\n",
    "        if pd.isna(cat_str):\n",
    "            return []\n",
    "        \n",
    "        # If already a list, return it (cleaned)\n",
    "        if isinstance(cat_str, list):\n",
    "            cleaned_cats = [str(cat).strip().strip(\"'\\\"\") for cat in cat_str]\n",
    "            return [cat for cat in cleaned_cats if cat and cat != \"''\" and cat != '\"\"']\n",
    "        \n",
    "        # If it's a string, try to parse it\n",
    "        if isinstance(cat_str, str):\n",
    "            cat_str = str(cat_str).strip()\n",
    "            \n",
    "            # Handle empty or meaningless strings\n",
    "            if not cat_str or cat_str in ['[]', \"''\", '\"\"', 'nan', 'null', 'none']:\n",
    "                return ['general']\n",
    "            \n",
    "            # Try to parse as JSON/list if it looks like one\n",
    "            try:\n",
    "                # Clean up common formatting issues\n",
    "                clean_str = cat_str.replace(\"'\", '\"')  # Standardize quotes\n",
    "                \n",
    "                # Handle brackets\n",
    "                if clean_str.startswith('[') and clean_str.endswith(']'):\n",
    "                    # Parse as JSON\n",
    "                    import json\n",
    "                    categories = json.loads(clean_str)\n",
    "                elif ',' in clean_str:\n",
    "                    # Split by comma (handling quotes properly)\n",
    "                    import re\n",
    "                    # Regex to split by commas not inside quotes\n",
    "                    categories = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', clean_str)\n",
    "                    categories = [cat.strip().strip('\"\\'') for cat in categories]\n",
    "                else:\n",
    "                    # Single category\n",
    "                    categories = [clean_str.strip('\"\\'')]\n",
    "                \n",
    "                # Clean and validate categories\n",
    "                cleaned_cats = []\n",
    "                for cat in categories:\n",
    "                    if isinstance(cat, str):\n",
    "                        cat = cat.strip().lower()\n",
    "                        if cat and cat not in ['', 'nan', 'null', 'none', 'unknown']:\n",
    "                            cleaned_cats.append(cat)\n",
    "                    elif isinstance(cat, (int, float)):\n",
    "                        # Convert numeric categories to string\n",
    "                        cleaned_cats.append(str(cat))\n",
    "                \n",
    "                # Return 'general' if no valid categories found\n",
    "                return cleaned_cats if cleaned_cats else ['general']\n",
    "                \n",
    "            except Exception as e:\n",
    "                # If parsing fails, check for common patterns\n",
    "                # Check if it looks like it was meant to be a list but has formatting issues\n",
    "                if any(marker in cat_str for marker in ['[', ']', \"'\", '\"']):\n",
    "                    # Try manual extraction\n",
    "                    clean_str = cat_str.strip(\"[]'\\\"\")\n",
    "                    if clean_str:\n",
    "                        categories = [cat.strip().strip(\"'\\\"\") \n",
    "                                    for cat in clean_str.split(',')]\n",
    "                        valid_cats = [cat for cat in categories \n",
    "                                    if cat and cat not in ['', 'nan', 'null']]\n",
    "                        return valid_cats if valid_cats else ['general']\n",
    "                \n",
    "                # Check if it's a single valid category\n",
    "                clean_cat = cat_str.strip().strip(\"'\\\"\")\n",
    "                if clean_cat and clean_cat.lower() not in ['', 'nan', 'null', 'none', 'unknown']:\n",
    "                    return [clean_cat.lower()]\n",
    "                \n",
    "                # Default to general category\n",
    "                return ['general']\n",
    "        \n",
    "        # For any other data type, convert to string and process\n",
    "        try:\n",
    "            return extract_categories(str(cat_str))\n",
    "        except:\n",
    "            return ['general']\n",
    "    \n",
    "    # Apply the fix\n",
    "    Job_df['categories_fixed'] = Job_df['Category_list'].apply(extract_categories)\n",
    "    \n",
    "    # Replace empty lists with ['general']\n",
    "    Job_df['categories_fixed'] = Job_df['categories_fixed'].apply(\n",
    "        lambda x: ['general'] if not x else x\n",
    "    )\n",
    "    \n",
    "    # Count categories again\n",
    "    all_categories_fixed = []\n",
    "    for categories in Job_df['categories_fixed']:\n",
    "        all_categories_fixed.extend(categories)\n",
    "    \n",
    "    category_counts_fixed = pd.Series(all_categories_fixed).value_counts().head(15)\n",
    "    \n",
    "    print(f\"\\n Fixed Category Extraction Results:\")\n",
    "    print(\"-\"*60)\n",
    "    total_cats = len(all_categories_fixed)\n",
    "    for category, count in category_counts_fixed.items():\n",
    "        pct = (count / total_cats) * 100\n",
    "        print(f\"{category:40}: {count:5,d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Check if 'unknown' is still present\n",
    "    unknown_count = sum(1 for cat in all_categories_fixed if cat == 'unknown')\n",
    "    general_count = sum(1 for cat in all_categories_fixed if cat == 'general')\n",
    "    \n",
    "    print(f\"\\ Category Statistics:\")\n",
    "    print(f\"    Total category mentions: {total_cats:,}\")\n",
    "    print(f\"    Unique categories: {len(set(all_categories_fixed)):,}\")\n",
    "    print(f\"    'general' categories: {general_count:,}\")\n",
    "    print(f\"    'unknown' categories: {unknown_count:,}\")\n",
    "    \n",
    "    if unknown_count > 0:\n",
    "        print(f\"\\n  Still have {unknown_count:,} 'unknown' categories\")\n",
    "        print(\"   Showing samples with 'unknown':\")\n",
    "        unknown_samples = Job_df[Job_df['categories_fixed'].apply(lambda x: 'unknown' in x)]\n",
    "        for i, (idx, row) in enumerate(unknown_samples.head(3).iterrows(), 1):\n",
    "            print(f\"   {i}. Original: {row['Category_list']} -> Fixed: {row['categories_fixed']}\")\n",
    "    \n",
    "    # Update the insights\n",
    "    top_category = category_counts_fixed.index[0] if len(category_counts_fixed) > 0 else \"N/A\"\n",
    "    top_category_count = category_counts_fixed.iloc[0] if len(category_counts_fixed) > 0 else 0\n",
    "    print(f\"\\n Corrected Top Category: '{top_category}' with {top_category_count:,} mentions\")\n",
    "    \n",
    "    # Show distribution of list lengths\n",
    "    print(f\"\\n Category list length distribution:\")\n",
    "    list_lengths = Job_df['categories_fixed'].apply(len).value_counts().sort_index()\n",
    "    for length, count in list_lengths.items():\n",
    "        pct = (count / len(Job_df)) * 100\n",
    "        print(f\"    {length} category/categories: {count:5,d} jobs ({pct:5.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\" Category_list column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Text Features\n",
    "\n",
    "In this section, we engineer structured numerical and binary features from the `Description` column. \n",
    "Rather than immediately applying advanced NLP techniques (e.g., TF-IDF or embeddings), we first extract interpretable and lightweight text features that may improve model performance Specifically, we aim to:\n",
    "- Capture description length and complexity\n",
    "- Identify the presence of requirement-related language\n",
    "- Detect educational qualification requirements\n",
    "- Convert textual patterns into structured numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.1 TEXT FEATURE ENGINEERING\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fefd03bfaa4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 1. Basic text features from Description\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'Description'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating text-based features from job descriptions...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header Formatting\n",
    "print(\"5.2.1 TEXT FEATURE ENGINEERING\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 1. Basic text features from Description\n",
    "if 'Description' in Job_df.columns:\n",
    "    print(\"Creating text-based features from job descriptions...\")\n",
    "    \n",
    "    # Text length features\n",
    "    Job_df['desc_word_count'] = Job_df['Description'].apply(lambda x: len(str(x).split()))\n",
    "    Job_df['desc_char_count'] = Job_df['Description'].apply(lambda x: len(str(x)))\n",
    "    Job_df['desc_avg_word_length'] = Job_df['desc_char_count'] / (Job_df['desc_word_count'] + 1)  # +1 to avoid division by zero\n",
    "    \n",
    "    # Check for requirements keywords\n",
    "    requirements_keywords = ['experience', 'skills', 'qualifications', 'requirements', 'must have', 'should have']\n",
    "    for keyword in requirements_keywords:\n",
    "        Job_df[f'desc_has_{keyword}'] = Job_df['Description'].str.contains(keyword, case=False, na=False).astype(int)\n",
    "    \n",
    "    # Check for degree requirements\n",
    "    degree_keywords = ['bachelor', 'master', 'phd', 'degree', 'bs', 'ms', 'ba', 'ma']\n",
    "    for degree in degree_keywords:\n",
    "        Job_df[f'desc_requires_{degree}'] = Job_df['Description'].str.contains(degree, case=False, na=False).astype(int)\n",
    "    \n",
    "    print(f\" Created {len(requirements_keywords) + len(degree_keywords) + 3} text features\")\n",
    "    \n",
    "    # Show text feature statistics\n",
    "    print(f\"\\n Text Feature Statistics:\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"   Average word count: {Job_df['desc_word_count'].mean():.0f}\")\n",
    "    print(f\"   Average character count: {Job_df['desc_char_count'].mean():.0f}\")\n",
    "    print(f\"   Descriptions mentioning 'experience': {(Job_df['desc_has_experience'].sum()/len(Job_df)*100):.1f}%\")\n",
    "    print(f\"   Descriptions mentioning 'degree': {(Job_df['desc_requires_degree'].sum()/len(Job_df)*100):.1f}%\")\n",
    "else:\n",
    "    print(\"Description column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Geographical Features\n",
    "\n",
    "Geographic information can significantly influence job characteristics such as salary levels, job demand, and hiring trends. However, location variables like country and state often contain many unique values (high cardinality), which can negatively impact model performance if encoded directly.\n",
    "\n",
    "In this section, we engineer structured geographic features to capture meaningful location patterns while controlling dimensionality and reducing sparsi. We aim to:\n",
    "- Reduce high-cardinality categorical variables  \n",
    "- Capture broader regional trends  \n",
    "- Create meaningful binary indicators  \n",
    "- Handle rare and missing geographic values appropriately  \n",
    ".ives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.2 GEOGRAPHIC FEATURE ENGINEERING\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-1437a0adf6fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create geographic hierarchy features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'country'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating geographic features...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header Formatting\n",
    "\n",
    "print(\"5.2.2 GEOGRAPHIC FEATURE ENGINEERING\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Create geographic hierarchy features\n",
    "if 'country' in Job_df.columns:\n",
    "    print(\"Creating geographic features...\")\n",
    "    \n",
    "    # Country encoding (one-hot for top countries)\n",
    "    top_countries = Job_df['country'].value_counts().head(10).index.tolist()\n",
    "    Job_df['country_top'] = Job_df['country'].apply(lambda x: x if x in top_countries else 'Other')\n",
    "    \n",
    "    # Continent features\n",
    "    if 'continent' in Job_df.columns:\n",
    "        # One-hot encode continents\n",
    "        continent_dummies = pd.get_dummies(Job_df['continent'], prefix='continent')\n",
    "        Job_df = pd.concat([Job_df, continent_dummies], axis=1)\n",
    "    \n",
    "    # US state features (if applicable)\n",
    "    us_mask = Job_df['country'].str.contains('United States|USA|US', case=False, na=False)\n",
    "    if us_mask.any():\n",
    "        Job_df['is_us'] = us_mask.astype(int)\n",
    "        \n",
    "        if 'state' in Job_df.columns:\n",
    "            top_states = Job_df.loc[us_mask, 'state'].value_counts().head(10).index.tolist()\n",
    "            Job_df['state_top'] = Job_df['state'].apply(lambda x: x if x in top_states else ('Other' if pd.notna(x) else 'Unknown'))\n",
    "    \n",
    "    print(f\" Created geographic features\")\n",
    "    print(f\"   Top countries identified: {len(top_countries)}\")\n",
    "    print(f\"   US jobs: {us_mask.sum():,} ({us_mask.sum()/len(Job_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"Country column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Company Features\n",
    "\n",
    "Company-level characteristics can provide strong signals about hiring behavior, job stability, and market presence. However, company names are high-cardinality categorical variables, making direct encoding inefficient and prone to overfitting.\n",
    "\n",
    "In this section, we engineer aggregated company-level features that capture organizational scale, dominance, and hiring intensity without introducing excessive dimensionalit We aim to:\n",
    "- Transform raw company names into meaningful numerical or grouped features  \n",
    "- Capture organizational scale using posting frequency  \n",
    "- Identify dominant companies in the dataset  \n",
    "- Measure hiring intens over time \n",
    "y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.3 COMPANY FEATURE ENGINEERING\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-96d498b691b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Company-based features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'company_name'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating company-based features...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"5.2.3 COMPANY FEATURE ENGINEERING\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Company-based features\n",
    "if 'company_name' in Job_df.columns:\n",
    "    print(\"Creating company-based features...\")\n",
    "    \n",
    "    # Company size (based on number of postings)\n",
    "    company_post_counts = Job_df['company_name'].value_counts()\n",
    "    \n",
    "    # Categorize companies by size\n",
    "    def categorize_company_size(company):\n",
    "        count = company_post_counts.get(company, 0)\n",
    "        if count > 1000:\n",
    "            return 'very_large'\n",
    "        elif count > 100:\n",
    "            return 'large'\n",
    "        elif count > 10:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'small'\n",
    "    \n",
    "    Job_df['company_size'] = Job_df['company_name'].apply(categorize_company_size)\n",
    "    \n",
    "    # Top company indicator\n",
    "    top_companies = company_post_counts.head(5).index.tolist()\n",
    "    Job_df['is_top_company'] = Job_df['company_name'].isin(top_companies).astype(int)\n",
    "    \n",
    "    # Company posting frequency (jobs per day if we have date data)\n",
    "    if 'First Seen At' in Job_df.columns and pd.api.types.is_datetime64_any_dtype(Job_df['First Seen At']):\n",
    "        # Calculate company activity rate\n",
    "        company_first_post = Job_df.groupby('company_name')['First Seen At'].min()\n",
    "        company_last_post = Job_df.groupby('company_name')['First Seen At'].max()\n",
    "        \n",
    "        # Days active\n",
    "        company_days_active = (company_last_post - company_first_post).dt.days + 1  # +1 to avoid division by zero\n",
    "        company_post_rate = company_post_counts / company_days_active\n",
    "        \n",
    "        # Map back to dataframe\n",
    "        company_rate_dict = company_post_rate.to_dict()\n",
    "        Job_df['company_post_rate'] = Job_df['company_name'].map(company_rate_dict)\n",
    "        Job_df['company_post_rate'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\" Created company features\")\n",
    "    print(f\"  Company size distribution:\")\n",
    "    print(Job_df['company_size'].value_counts())\n",
    "    print(f\"   Top companies identified: {len(top_companies)}\")\n",
    "else:\n",
    "    print(\"company_name column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Temporal Features\n",
    "\n",
    "Job posting behavior often follows clear temporal patterns influenced by hiring cycles, budgeting periods, and work-week dynamics. Capturing when a job is posted can therefore provide valuable signals about demand intensity, urgency, and employer behavior.\n",
    "\n",
    "In this section, we extract structured time-based features from the job posting timestamps to model seasonal, weekly, and recency-related trend We aim to:\n",
    "- Capture seasonal and quarterly hiring patterns  \n",
    "- Differentiate weekday vs weekend posting behavior  \n",
    "- Extract temporal signals related to job posting recency  \n",
    "- Transform raw timestamps into model-friendly features  s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.4 TEMPORAL FEATURE ENGINEERING\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-1c1700413da6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Time-based features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'First Seen At'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_datetime64_any_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'First Seen At'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating temporal features...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"5.2.4 TEMPORAL FEATURE ENGINEERING\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Time-based features\n",
    "if 'First Seen At' in Job_df.columns and pd.api.types.is_datetime64_any_dtype(Job_df['First Seen At']):\n",
    "    print(\"Creating temporal features...\")\n",
    "    \n",
    "    # Time of year features\n",
    "    Job_df['post_month'] = Job_df['First Seen At'].dt.month\n",
    "    Job_df['post_quarter'] = Job_df['First Seen At'].dt.quarter\n",
    "    Job_df['post_dayofweek'] = Job_df['First Seen At'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    \n",
    "    # Seasonal features\n",
    "    Job_df['is_q1'] = (Job_df['post_quarter'] == 1).astype(int)\n",
    "    Job_df['is_q2'] = (Job_df['post_quarter'] == 2).astype(int)\n",
    "    Job_df['is_q3'] = (Job_df['post_quarter'] == 3).astype(int)\n",
    "    Job_df['is_q4'] = (Job_df['post_quarter'] == 4).astype(int)\n",
    "    \n",
    "    # Weekend vs weekday\n",
    "    Job_df['is_weekend'] = Job_df['post_dayofweek'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Time since first post (recency)\n",
    "    if 'posting_duration_days' not in Job_df.columns and 'Last Seen At' in Job_df.columns:\n",
    "        Job_df['posting_duration_days'] = (Job_df['Last Seen At'] - Job_df['First Seen At']).dt.days\n",
    "    \n",
    "    print(f\" Created temporal features\")\n",
    "    print(f\"   Month distribution: {Job_df['post_month'].value_counts().sort_index().to_dict()}\")\n",
    "    print(f\"   Weekend posts: {Job_df['is_weekend'].sum():,} ({Job_df['is_weekend'].sum()/len(Job_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"Date columns not available for temporal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 Composite Features\n",
    "\n",
    "While individual features capture isolated signals, many real-world patterns emerge from **interactions between variables**. Composite feature engineering focuses on combining related attributes to expose higher-order relationships that may better reflect job complexity, seniority, and role specialization.\n",
    "\n",
    "In this section, we construct interaction and aggregation features that blend seniority, job categories, title indicators, and organizational contex We aim to:\n",
    "- Capture interactions between seniority and job function  \n",
    "- Quantify role complexity using multiple title indicators  \n",
    "- Identify technical specialization within job categories  \n",
    "- Lay groundwork for future companylocation interaction features  t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.5 COMPOSITE FEATURE ENGINEERING\n",
      "----------------------------------------------------------------------\n",
      " Creating composite features...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f4cef4db18b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 1. Seniority-Category combinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'Seniority_clean'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'categories_fixed'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Create seniority-category interaction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     Job_df['seniority_level'] = Job_df['Seniority_clean'].map({\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header formatting\n",
    "print(\"5.2.5 COMPOSITE FEATURE ENGINEERING\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\" Creating composite features...\")\n",
    "\n",
    "# 1. Seniority-Category combinations\n",
    "if 'Seniority_clean' in Job_df.columns and 'categories_fixed' in Job_df.columns:\n",
    "    # Create seniority-category interaction\n",
    "    Job_df['seniority_level'] = Job_df['Seniority_clean'].map({\n",
    "        'individual_contributor': 1,\n",
    "        'manager': 2,\n",
    "        'director_level': 3,\n",
    "        'executive': 4,\n",
    "        'other': 0\n",
    "    }).fillna(0)\n",
    "    \n",
    "    # Count categories per job\n",
    "    Job_df['num_categories'] = Job_df['categories_fixed'].apply(len)\n",
    "    \n",
    "    # Has technical category flag\n",
    "    technical_categories = ['engineering', 'software_development', 'information_technology', 'data_science']\n",
    "    Job_df['has_technical_category'] = Job_df['categories_fixed'].apply(\n",
    "        lambda cats: any(tech_cat in str(cats) for tech_cat in technical_categories)\n",
    "    ).astype(int)\n",
    "\n",
    "# 2. Title-Composite features\n",
    "title_indicators = ['title_has_senior', 'title_has_manager', 'title_has_engineer', 'title_has_developer']\n",
    "existing_title_indicators = [ind for ind in title_indicators if ind in Job_df.columns]\n",
    "\n",
    "if existing_title_indicators:\n",
    "    # Create title complexity score\n",
    "    Job_df['title_complexity'] = Job_df[existing_title_indicators].sum(axis=1)\n",
    "    \n",
    "    # Senior engineer flag\n",
    "    if 'title_has_senior' in Job_df.columns and 'title_has_engineer' in Job_df.columns:\n",
    "        Job_df['is_senior_engineer'] = (Job_df['title_has_senior'] & Job_df['title_has_engineer']).astype(int)\n",
    "\n",
    "# 3. Location-Company interactions\n",
    "if 'country' in Job_df.columns and 'company_name' in Job_df.columns:\n",
    "    # Company-country presence (just create a count for now)\n",
    "    company_country_counts = Job_df.groupby(['company_name', 'country']).size()\n",
    "    # We can use this later if needed\n",
    "\n",
    "print(f\" Created composite features\")\n",
    "print(f\"   Total features after engineering: {len(Job_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Feature Selection\n",
    "\n",
    "After completing feature engineering, the next step is to systematically organize and prepare features for modeling. Rather than manually selecting columns, we group engineered features into logical categories and dynamically identify which ones are available in the dataset.\n",
    "This ensures:\n",
    "- Structured feature organization  \n",
    "- Flexibility if certain columns are missing  \n",
    "- Scalability for future feature additions  \n",
    "- Cleaner modeling pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3 FEATURE SELECTION & PREPARATION\n",
      "----------------------------------------------------------------------\n",
      "Categorizing features for modeling...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-9a57e8516203>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mmatching_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mavailable_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mavailable_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Header Formatting\n",
    "print(\"5.3 FEATURE SELECTION & PREPARATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Define feature categories\n",
    "print(\"Categorizing features for modeling...\")\n",
    "\n",
    "feature_categories = {\n",
    "    'Geographic': ['country_top', 'is_us', 'continent_*'],\n",
    "    'Company': ['company_size', 'is_top_company', 'company_post_rate'],\n",
    "    'Temporal': ['post_month', 'post_quarter', 'post_dayofweek', 'is_weekend', 'posting_duration_days'],\n",
    "    'Text': ['desc_word_count', 'desc_char_count', 'desc_avg_word_length', 'desc_has_*', 'desc_requires_*'],\n",
    "    'Seniority': ['Seniority_clean', 'seniority_level'],\n",
    "    'Title': ['title_has_*', 'title_complexity', 'is_senior_engineer'],\n",
    "    'Category': ['num_categories', 'has_technical_category'],\n",
    "    'Contract': ['Contract_Type_primary']\n",
    "}\n",
    "\n",
    "# Identify available features\n",
    "available_features = []\n",
    "for category, features in feature_categories.items():\n",
    "    for feature in features:\n",
    "        if '*' in feature:\n",
    "            # Pattern matching for wildcards\n",
    "            pattern = feature.replace('*', '.*')\n",
    "            matching_features = [col for col in Job_df.columns if re.match(pattern, col)]\n",
    "            available_features.extend(matching_features)\n",
    "        elif feature in Job_df.columns:\n",
    "            available_features.append(feature)\n",
    "\n",
    "print(f\"\\n Available features for modeling: {len(available_features)}\")\n",
    "print(f\"\\nFeature breakdown by category:\")\n",
    "\n",
    "# Count features by category\n",
    "for category in feature_categories.keys():\n",
    "    cat_features = [f for f in available_features if any(f.startswith(prefix.replace('*', '')) \n",
    "                     for prefix in feature_categories[category] if '*' in prefix) or \n",
    "                     f in feature_categories[category]]\n",
    "    if cat_features:\n",
    "        print(f\"   {category:15}: {len(cat_features):2d} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Target Variable Definition\n",
    "\n",
    "After completing feature engineering and selection, the next step is to define the **target variable(s)** for supervised modeling. \n",
    "\n",
    "This section dynamically constructs and evaluates several potential target variables based on data availability and class balanc The aim is to:\n",
    "- Define meaningful prediction targets  \n",
    "- Ensure sufficient class representation  \n",
    "- Prevent extreme class imbalance  \n",
    "- Enable flexible experimentation across multiple modeling taskse.\n",
    "g tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4 TARGET VARIABLE DEFINITION\n",
      "----------------------------------------------------------------------\n",
      "Defining target variables for modeling...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-30d39bca715c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Option 1: Job Category Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'categories_fixed'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Create simplified category target (primary category)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     Job_df['primary_category'] = Job_df['categories_fixed'].apply(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header Formatting\n",
    "print(\"5.4 TARGET VARIABLE DEFINITION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"Defining target variables for modeling...\")\n",
    "\n",
    "target_options = []\n",
    "\n",
    "# Option 1: Job Category Prediction\n",
    "if 'categories_fixed' in Job_df.columns:\n",
    "    # Create simplified category target (primary category)\n",
    "    Job_df['primary_category'] = Job_df['categories_fixed'].apply(\n",
    "        lambda cats: cats[0] if cats and len(cats) > 0 else 'unknown'\n",
    "    )\n",
    "    \n",
    "    # Only use categories with sufficient samples\n",
    "    category_counts = Job_df['primary_category'].value_counts()\n",
    "    min_samples = 50  # Minimum samples per category\n",
    "    valid_categories = category_counts[category_counts >= min_samples].index.tolist()\n",
    "    \n",
    "    Job_df['category_target'] = Job_df['primary_category'].apply(\n",
    "        lambda x: x if x in valid_categories else 'other'\n",
    "    )\n",
    "    \n",
    "    target_options.append((\"Category Prediction\", f\"{Job_df['category_target'].nunique()} categories\"))\n",
    "    print(f\" Category target: {Job_df['category_target'].nunique()} classes\")\n",
    "    print(f\"   Top categories: {Job_df['category_target'].value_counts().head(5).to_dict()}\")\n",
    "\n",
    "# Option 2: Seniority Level Prediction\n",
    "if 'Seniority_clean' in Job_df.columns:\n",
    "    seniority_counts = Job_df['Seniority_clean'].value_counts()\n",
    "    valid_seniority = seniority_counts[seniority_counts >= 50].index.tolist()\n",
    "    \n",
    "    Job_df['seniority_target'] = Job_df['Seniority_clean'].apply(\n",
    "        lambda x: x if x in valid_seniority else 'other'\n",
    "    )\n",
    "    \n",
    "    target_options.append((\"Seniority Prediction\", f\"{Job_df['seniority_target'].nunique()} levels\"))\n",
    "    print(f\" Seniority target: {Job_df['seniority_target'].nunique()} classes\")\n",
    "\n",
    "# Option 3: Geographic Prediction (US vs Non-US)\n",
    "if 'country' in Job_df.columns:\n",
    "    Job_df['us_target'] = Job_df['country'].str.contains('United States|USA|US', case=False, na=False).astype(int)\n",
    "    target_options.append((\"US Job Prediction\", \"Binary classification\"))\n",
    "    print(f\" US target: {Job_df['us_target'].sum():,} US jobs ({Job_df['us_target'].sum()/len(Job_df)*100:.1f}%)\")\n",
    "\n",
    "# Option 4: Full-time vs Other\n",
    "if 'Contract_Type_primary' in Job_df.columns:\n",
    "    Job_df['fulltime_target'] = (Job_df['Contract_Type_primary'] == 'full_time').astype(int)\n",
    "    target_options.append((\"Full-time Prediction\", \"Binary classification\"))\n",
    "    print(f\" Full-time target: {Job_df['fulltime_target'].sum():,} full-time jobs ({Job_df['fulltime_target'].sum()/len(Job_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Available target variables:\")\n",
    "for i, (target_name, description) in enumerate(target_options, 1):\n",
    "    print(f\"{i:2}. {target_name:25} - {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Feature Encoding and Scaling\n",
    "\n",
    "After defining the target variable and selecting relevant predictors, the next step is to prepare the feature matrix for machine learning. \n",
    "\n",
    "This section performs feature selection, categorical encoding, missing value handling, and feature scaling to produce a model-ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5 FEATURE ENCODING & SCALING\n",
      "----------------------------------------------------------------------\n",
      "Preparing features for machine learning...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-a9606218b119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m'desc_word_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;34m'desc_char_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;34m'is_us'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'is_us'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;34m'company_size'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'company_size'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;34m'post_month'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'post_month'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Header Formatting\n",
    "print(\"5.5 FEATURE ENCODING & SCALING\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"Preparing features for machine learning...\")\n",
    "\n",
    "# Select features for modeling (basic set to start)\n",
    "basic_features = [\n",
    "    'seniority_level',\n",
    "    'num_categories',\n",
    "    'has_technical_category',\n",
    "    'desc_word_count',\n",
    "    'desc_char_count',\n",
    "    'is_us' if 'is_us' in Job_df.columns else None,\n",
    "    'company_size' if 'company_size' in Job_df.columns else None,\n",
    "    'post_month' if 'post_month' in Job_df.columns else None,\n",
    "    'posting_duration_days' if 'posting_duration_days' in Job_df.columns else None\n",
    "]\n",
    "\n",
    "# Filter out None values\n",
    "basic_features = [f for f in basic_features if f is not None and f in Job_df.columns]\n",
    "\n",
    "print(f\"\\n Selected {len(basic_features)} basic features for initial modeling:\")\n",
    "for feature in basic_features:\n",
    "    print(f\"   - {feature}\")\n",
    "\n",
    "# Prepare feature matrix X\n",
    "X = Job_df[basic_features].copy()\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\"\\n Encoding categorical features: {categorical_cols}\")\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].fillna('missing'))\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"\\n Handling missing values...\")\n",
    "missing_before = X.isnull().sum().sum()\n",
    "X = X.fillna(X.median(numeric_only=True))  # For numerical features\n",
    "missing_after = X.isnull().sum().sum()\n",
    "print(f\"   Fixed {missing_before - missing_after} missing values\")\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\n Feature preparation complete:\")\n",
    "print(f\"   Feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"   Samples: {X_scaled.shape[0]}\")\n",
    "print(f\"   Features: {X_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Job Category Classification:\n",
    "   Type: Multi-class Classification\n",
    "   Target: category_target\n",
    "   Algorithms: Random Forest, XGBoost, Logistic Regression (One-vs-Rest)\n",
    "   Use Case: Automated job categorization for recruiters\n",
    "\n",
    "2. Seniority Level Prediction:\n",
    "   Type: Multi-class Classification\n",
    "   Target: seniority_target\n",
    "   Algorithms: Random Forest, Gradient Boosting, SVM\n",
    "   Use Case: Experience level estimation for job matching\n",
    "\n",
    "3. US Job Prediction:\n",
    "   Type: Binary Classification\n",
    "   Target: us_target\n",
    "   Algorithms: Logistic Regression, Random Forest, Neural Network\n",
    "   Use Case: Geographic opportunity identification\n",
    "\n",
    "4. Full-time Job Prediction:\n",
    "   Type: Binary Classification\n",
    "   Target: fulltime_target\n",
    "   Algorithms: Logistic Regression, XGBoost, Decision Tree\n",
    "   Use Case: Contract type classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[1;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[0;32m    873\u001b[0m     \"\"\"\n\u001b[1;32m--> 874\u001b[1;33m     \u001b[0mconfig_from_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-v0_8-darkgrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-9b2ec0476d65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set visualization style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-v0_8-darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"husl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 raise IOError(\n\u001b[0m\u001b[0;32m    125\u001b[0m                     \u001b[1;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn-v0_8-darkgrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "\n",
    "print(f\" Primary Modeling Task: Job Category Classification\")\n",
    "print(f\" Target: category_target ({len(np.unique(y_encoded))} classes)\")\n",
    "print(f\" Feature matrix: {X_scaled.shape[0]} samples  {X_scaled.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-311c53981e78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data split completed:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X_scaled)*100:.1f}%)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"Data split completed:\")\n",
    "print(f\"   Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
    "print(f\"   Test set:     {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
    "print(f\"   Features:     {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class distribution in training set:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-465fb3613b79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Checking class distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Class distribution in training set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0munique_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Checking class distribution\n",
    "print(f\" Class distribution in training set:\")\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "for class_idx, count in zip(unique_train, counts_train):\n",
    "    class_name = class_names[class_idx]\n",
    "    percentage = count / len(y_train) * 100\n",
    "    print(f\"   {class_name:25}: {count:4,d} ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will  go ahead and set our baseline model. \n",
    "We went with a Dummy classifier as our baseline model since our primary problem is a classification problem. \n",
    "This will set the baseline for which our other models will be expected to surpass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DummyClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-f316c568cf7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create and train dummy classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stratified'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DummyClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Create and train dummy classifier\n",
    "dummy = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "# Evaluate dummy classifier\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "print(f\" Dummy Classifier (Stratified) Performance:\")\n",
    "print(f\"   Accuracy: {accuracy_dummy:.4f}\")\n",
    "print(f\"   Baseline to beat: {accuracy_dummy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Random Forest\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-fd7a420ff5c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" Training Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\" Training Random Forest\")\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-0edb3834b12f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_pred_proba_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-288ebf8d5685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest Training Complete\n",
      " Performance Metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-0a3370245ad3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Random Forest Training Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Performance Metrics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Accuracy:  {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Precision: {precision_rf:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Recall:    {recall_rf:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_rf' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Random Forest Training Complete\")\n",
    "print(f\" Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_rf:.4f}\")\n",
    "print(f\"   Recall:    {recall_rf:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-7c291cc2a897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compare with baseline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimprovement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy_rf\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy_dummy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0maccuracy_dummy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Improvement over baseline: {improvement:+.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_rf' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare with baseline\n",
    "improvement = (accuracy_rf - accuracy_dummy) / accuracy_dummy * 100\n",
    "print(f\" Improvement over baseline: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running 5-fold cross-validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-45dc64d9c30a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Running 5-fold cross-validation...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Cross-validation scores: {cv_scores}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Mean CV accuracy: {cv_scores.mean():.4f} ({cv_scores.std():.4f})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "print(f\" Running 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"   Cross-validation scores: {cv_scores}\")\n",
    "print(f\"   Mean CV accuracy: {cv_scores.mean():.4f} ({cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000,random_state=42,n_jobs=-1,multi_class='ovr')  # One-vs-Rest for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-9752188f5137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-b8fae556ce4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression Training Complete\n",
      " Performance Metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-d3661fd78a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Logistic Regression Training Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Performance Metrics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Accuracy:  {accuracy_lr:.4f} ({accuracy_lr*100:.2f}%)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Precision: {precision_lr:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Recall:    {recall_lr:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_lr' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Logistic Regression Training Complete\")\n",
    "print(f\" Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {accuracy_lr:.4f} ({accuracy_lr*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_lr:.4f}\")\n",
    "print(f\"   Recall:    {recall_lr:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running 5-fold cross-validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b9b26a9cba86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Running 5-fold cross-validation...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv_scores_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Cross-validation scores: {cv_scores_lr}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Mean CV accuracy: {cv_scores_lr.mean():.4f} ({cv_scores_lr.std():.4f})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "print(f\"\\n Running 5-fold cross-validation...\")\n",
    "cv_scores_lr = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"   Cross-validation scores: {cv_scores_lr}\")\n",
    "print(f\"   Mean CV accuracy: {cv_scores_lr.mean():.4f} ({cv_scores_lr.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-42fcf46cfd00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Initialize XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Initialize XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m xgb_model = XGBClassifier(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost\n",
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-5320337ef827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-fbd93b28df98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Performance Metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-673584b2a36f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Performance Metrics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Accuracy:  {accuracy_xgb:.4f} ({accuracy_xgb*100:.2f}%)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Precision: {precision_xgb:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Recall:    {recall_xgb:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   F1-Score:  {f1_xgb:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {accuracy_xgb:.4f} ({accuracy_xgb*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_xgb:.4f}\")\n",
    "print(f\"   Recall:    {recall_xgb:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running 5-fold cross-validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-beb759b72e64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Running 5-fold cross-validation...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv_scores_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Cross-validation scores: {cv_scores_xgb}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Mean CV accuracy: {cv_scores_xgb.mean():.4f} ({cv_scores_xgb.std():.4f})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "print(f\" Running 5-fold cross-validation...\")\n",
    "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"   Cross-validation scores: {cv_scores_xgb}\")\n",
    "print(f\"   Mean CV accuracy: {cv_scores_xgb.mean():.4f} ({cv_scores_xgb.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our baseline dummy classifier achieve an accuracr of **11.2%** which is a very low score. Our other three models\n",
    "achieved an average accuracy of **58%** which is a considerable improvement with the XGBoost Classifer showing the most significant improvement with an accuracy sore of **60%**.\n",
    "\n",
    "\n",
    "We however noted that the accuracy scores showed that the models are still not sufficient enough for our dataset. Therefore, we deployed some improvement strategies as follows;\n",
    "\n",
    "\n",
    "\n",
    "1.Handle class imbalance with class weights\n",
    "\n",
    "2.Add enhanced text features\n",
    "\n",
    "3.Create interaction features\n",
    "\n",
    "4.Implement model stacking\n",
    "\n",
    "5.Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Enhanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basic_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-28276db2e3db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 2. Prepare Enhanced Feature Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Start with basic features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menhanced_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasic_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Add new text features if they exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'basic_features' is not defined"
     ]
    }
   ],
   "source": [
    "## 2. Prepare Enhanced Feature Matrix\n",
    "# Start with basic features\n",
    "enhanced_features = basic_features.copy()\n",
    "\n",
    "# Add new text features if they exist\n",
    "text_features_to_add = [\n",
    "    'desc_has_python', 'desc_has_sql', 'desc_has_aws', 'desc_has_java',\n",
    "    'desc_has_javascript', 'desc_has_cloud', 'desc_has_devops', \n",
    "    'desc_has_machine_learning', 'desc_code_indicators', 'desc_bullet_points'\n",
    "]\n",
    "\n",
    "for feature in text_features_to_add:\n",
    "    if feature in Job_df.columns:\n",
    "        enhanced_features.append(feature)\n",
    "        print(f\"   Added: {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-d5e1ed51e420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. Seniority  Company Size interaction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'seniority_level'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'company_size'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Encode company_size numerically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcompany_size_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'small'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'medium'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'large'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'very_large'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company_size_encoded'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompany_size_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Seniority  Company Size interaction\n",
    "if 'seniority_level' in Job_df.columns and 'company_size' in Job_df.columns:\n",
    "    # Encode company_size numerically\n",
    "    company_size_map = {'small': 1, 'medium': 2, 'large': 3, 'very_large': 4}\n",
    "    Job_df['company_size_encoded'] = Job_df['company_size'].map(company_size_map).fillna(0)\n",
    "    \n",
    "    # Create interaction\n",
    "    Job_df['seniority_company_interaction'] = Job_df['seniority_level'] * Job_df['company_size_encoded']\n",
    "    enhanced_features.append('seniority_company_interaction')\n",
    "    print(f\"   Added: seniority_company_interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-f4cdafe0105c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2. Technical  US interaction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'has_technical_category'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'is_us'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'technical_us_interaction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_technical_category'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_us'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0menhanced_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'technical_us_interaction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Added: technical_us_interaction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Technical  US interaction\n",
    "if 'has_technical_category' in Job_df.columns and 'is_us' in Job_df.columns:\n",
    "    Job_df['technical_us_interaction'] = Job_df['has_technical_category'] * Job_df['is_us']\n",
    "    enhanced_features.append('technical_us_interaction')\n",
    "    print(f\"   Added: technical_us_interaction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-31e01ac04283>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 3. Description length  Number of categories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'desc_word_count'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'num_categories'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'desc_length_category_interaction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'desc_word_count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_categories'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0menhanced_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'desc_length_category_interaction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Added: desc_length_category_interaction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Description length  Number of categories\n",
    "if 'desc_word_count' in Job_df.columns and 'num_categories' in Job_df.columns:\n",
    "    Job_df['desc_length_category_interaction'] = Job_df['desc_word_count'] * Job_df['num_categories']\n",
    "    enhanced_features.append('desc_length_category_interaction')\n",
    "    print(f\"   Added: desc_length_category_interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enhanced_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-4ddf1a6d5091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Enhanced feature set: {len(enhanced_features)} features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'enhanced_features' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Enhanced feature set: {len(enhanced_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-37492bb407ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 2. Prepare Enhanced Feature Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_enhanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menhanced_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Handle categorical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "## 2. Prepare Enhanced Feature Matrix\n",
    "\n",
    "X_enhanced = Job_df[enhanced_features].copy()\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = X_enhanced.select_dtypes(include=['object']).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\" Encoding categorical features: {categorical_cols}\")\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_enhanced[col] = le.fit_transform(X_enhanced[col].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_enhanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-7a7cf2c58ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Handle missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmissing_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_enhanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_enhanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_enhanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_enhanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmissing_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_enhanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Fixed {missing_before - missing_after} missing values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_enhanced' is not defined"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "missing_before = X_enhanced.isnull().sum().sum()\n",
    "X_enhanced = X_enhanced.fillna(X_enhanced.median(numeric_only=True))\n",
    "missing_after = X_enhanced.isnull().sum().sum()\n",
    "print(f\" Fixed {missing_before - missing_after} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_enhanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-b0777c025dd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Scale features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler_enhanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_enhanced_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_enhanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_enhanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_enhanced' is not defined"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "scaler_enhanced = StandardScaler()\n",
    "X_enhanced_scaled = scaler_enhanced.fit_transform(X_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Enhanced feature matrix prepared:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_enhanced_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-7c8c39458961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Show feature list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Enhanced feature matrix prepared:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Shape: {X_enhanced_scaled.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Features: {len(enhanced_features)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Samples: {X_enhanced_scaled.shape[0]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_enhanced_scaled' is not defined"
     ]
    }
   ],
   "source": [
    " #Show feature list\n",
    "print(f\"\\n Enhanced feature matrix prepared:\")\n",
    "print(f\"   Shape: {X_enhanced_scaled.shape}\")\n",
    "print(f\"   Features: {len(enhanced_features)}\")\n",
    "print(f\"   Samples: {X_enhanced_scaled.shape[0]}\")\n",
    "\n",
    "# Show feature list\n",
    "print(f\" Enhanced Features ({len(enhanced_features)} total):\")\n",
    "for i, feature in enumerate(enhanced_features, 1):\n",
    "    print(f\"   {i:2}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-f75116e49c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get class distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_encoded' is not defined"
     ]
    }
   ],
   "source": [
    " # Get class distribution\n",
    "class_counts = np.bincount(y_encoded)\n",
    "total_samples = len(y_encoded)\n",
    "n_classes = len(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-135d1da3870e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate class weights (inverse frequency)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mclass_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate class weights (inverse frequency)\n",
    "class_weights = {}\n",
    "for class_idx in range(n_classes):\n",
    "    if class_counts[class_idx] > 0:\n",
    "        class_weights[class_idx] = total_samples / (n_classes * class_counts[class_idx])\n",
    "    else:\n",
    "        class_weights[class_idx] = 1.0\n",
    "\n",
    "print(f\"   Number of classes: {n_classes}\")\n",
    "print(f\"   Total samples: {total_samples:,}\")\n",
    "print(f\"   Min class size: {class_counts.min()}\")\n",
    "print(f\"   Max class size: {class_counts.max()}\")\n",
    "print(f\"   Class weights calculated (inverse frequency)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample Class Weights:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show some class weights\n",
    "print(f\" Sample Class Weights:\")\n",
    "for i, (class_idx, weight) in enumerate(list(class_weights.items())[:5]):\n",
    "    class_name = class_names[class_idx]\n",
    "    print(f\"   {class_name:25}: weight = {weight:.2f}, samples = {class_counts[class_idx]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_enhanced_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-3a32e92e670f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split data with enhanced features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_enh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_enhanced_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Data split with enhanced features:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Training set: {X_train_enh.shape[0]:,} samples\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Test set: {X_test_enh.shape[0]:,} samples\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_enhanced_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Split data with enhanced features\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(X_enhanced_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "print(f\"\\n Data split with enhanced features:\")\n",
    "print(f\"   Training set: {X_train_enh.shape[0]:,} samples\")\n",
    "print(f\"   Test set: {X_test_enh.shape[0]:,} samples\")\n",
    "print(f\"   Features: {X_train_enh.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Model Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-ac7f1d02f2ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     )),\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     ('xgb_weighted', XGBClassifier(\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ## 4. Implement Model Stacking with Class Weights\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# Define base models with class weights\n",
    "base_models = [\n",
    "    ('rf_weighted', RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=12,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=class_weights,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    \n",
    "    ('xgb_weighted', XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=len(y_train_enh[y_train_enh==0]) / len(y_train_enh[y_train_enh==1]) if len(np.unique(y_train_enh)) == 2 else 1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    )),\n",
    "    \n",
    "    ('lr_balanced', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        multi_class='ovr'\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-model\n",
    "meta_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-0ad6e2f34cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create stacking classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m stacking_model = StackingClassifier(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfinal_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_models' is not defined"
     ]
    }
   ],
   "source": [
    "# Create stacking classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True  # Use original features along with predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stacking classifier configured:\n",
      "   Base models: Weighted Random Forest, XGBoost, Balanced Logistic Regression\n",
      "   Meta-model: Balanced Logistic Regression\n",
      "   CV folds: 5\n"
     ]
    }
   ],
   "source": [
    "print(\" Stacking classifier configured:\")\n",
    "print(f\"   Base models: Weighted Random Forest, XGBoost, Balanced Logistic Regression\")\n",
    "print(f\"   Meta-model: Balanced Logistic Regression\")\n",
    "print(f\"   CV folds: 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stacking_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-794f5d882e23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train stacking model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstacking_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_enh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"  Training stacking model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_stacking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacking_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_enh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stacking_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train stacking model\n",
    "stacking_model.fit(X_train_enh, y_train_enh)\n",
    "print(f\"  Training stacking model...\")\n",
    "# Make predictions\n",
    "y_pred_stacking = stacking_model.predict(X_test_enh)\n",
    "y_pred_proba_stacking = stacking_model.predict_proba(X_test_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_enh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-74287e6777a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_stacking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_stacking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_stacking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_stacking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_stacking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_stacking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_stacking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_enh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_stacking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_enh' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_stacking = accuracy_score(y_test_enh, y_pred_stacking)\n",
    "precision_stacking = precision_score(y_test_enh, y_pred_stacking, average='weighted')\n",
    "recall_stacking = recall_score(y_test_enh, y_pred_stacking, average='weighted')\n",
    "f1_stacking = f1_score(y_test_enh, y_pred_stacking, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stacking Model Training Complete\n",
      " Performance Metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_stacking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-b670fb9bb1a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Stacking Model Training Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Performance Metrics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Accuracy:  {accuracy_stacking:.4f} ({accuracy_stacking*100:.2f}%)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Precision: {precision_stacking:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Recall:    {recall_stacking:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_stacking' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\" Stacking Model Training Complete\")\n",
    "print(f\" Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {accuracy_stacking:.4f} ({accuracy_stacking*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_stacking:.4f}\")\n",
    "print(f\"   Recall:    {recall_stacking:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_stacking:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running 5-fold cross-validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-5ccfd689359e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Running 5-fold cross-validation...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m cv_scores_stacking = cross_val_score(stacking_model, X_train_enh, y_train_enh, \n\u001b[0m\u001b[0;32m      4\u001b[0m                                      cv=5, scoring='accuracy', n_jobs=-1)\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Cross-validation scores: {cv_scores_stacking}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "print(f\" Running 5-fold cross-validation...\")\n",
    "cv_scores_stacking = cross_val_score(stacking_model, X_train_enh, y_train_enh, \n",
    "                                     cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"   Cross-validation scores: {cv_scores_stacking}\")\n",
    "print(f\"   Mean CV accuracy: {cv_scores_stacking.mean():.4f} ({cv_scores_stacking.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-20af4a5eab03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compare with previous best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprevious_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_xgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimprovement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy_stacking\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprevious_best\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mprevious_best\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Improvement over previous best (XGBoost): {improvement:+.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare with previous best\n",
    "previous_best = accuracy_xgb\n",
    "improvement = (accuracy_stacking - previous_best) / previous_best * 100\n",
    "print(f\" Improvement over previous best (XGBoost): {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-f13bcad28fb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train individual models with enhanced features for comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m models_enhanced = {\n\u001b[1;32m----> 3\u001b[1;33m     'XGBoost (Enhanced)': XGBClassifier(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Train individual models with enhanced features for comparison\n",
    "models_enhanced = {\n",
    "    'XGBoost (Enhanced)': XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'Random Forest (Enhanced)': RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=12,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=class_weights,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Logistic Regression (Enhanced)': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        multi_class='ovr'\n",
    "    )\n",
    "}\n",
    "\n",
    "results_enhanced = {}\n",
    "\n",
    "for model_name, model in models_enhanced.items():\n",
    "    print(f\"  Training {model_name}...\")\n",
    "    model.fit(X_train_enh, y_train_enh)\n",
    "    y_pred = model.predict(X_test_enh)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_enh, y_pred)\n",
    "    precision = precision_score(y_test_enh, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_enh, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_enh, y_pred, average='weighted')\n",
    "    \n",
    "    results_enhanced[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-44e403a4b43e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m comparison_data.append({\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'Model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'XGBoost (Original)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccuracy_xgb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;34m'F1-Score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf1_xgb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;34m'Features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'9 basic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# ## 6. Model Comparison\n",
    "comparison_data = []\n",
    "\n",
    "# Original models\n",
    "comparison_data.append({\n",
    "    'Model': 'XGBoost (Original)',\n",
    "    'Accuracy': accuracy_xgb,\n",
    "    'F1-Score': f1_xgb,\n",
    "    'Features': '9 basic',\n",
    "    'Class Handling': 'None'\n",
    "})\n",
    "\n",
    "# Enhanced individual models\n",
    "for model_name, metrics in results_enhanced.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'F1-Score': metrics['f1'],\n",
    "        'Features': f'{len(enhanced_features)} enhanced',\n",
    "        'Class Handling': 'Weighted/Balanced'\n",
    "    })\n",
    "\n",
    "# Stacking model\n",
    "comparison_data.append({\n",
    "    'Model': 'Stacking Ensemble',\n",
    "    'Accuracy': accuracy_stacking,\n",
    "    'F1-Score': f1_stacking,\n",
    "    'Features': f'{len(enhanced_features)} enhanced',\n",
    "    'Class Handling': 'Weighted + Stacking'\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\" Model Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-88121afff07a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visual comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comparison_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "models = comparison_df['Model']\n",
    "accuracies = comparison_df['Accuracy']\n",
    "\n",
    "bars = plt.bar(range(len(models)), accuracies, color=['lightgray', 'skyblue', 'lightgreen', 'salmon', 'gold'])\n",
    "plt.xticks(range(len(models)), models, rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison (Before vs After Improvements)', fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 0.7])\n",
    "plt.axhline(y=accuracy_dummy, color='red', linestyle='--', alpha=0.5, label=f'Baseline: {accuracy_dummy:.3f}')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 0.005,\n",
    "            f'{acc:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.4 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "6.4.4 HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "Performing hyperparameter tuning for Random Forest...\n",
      "Running grid search (this may take a few minutes)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-731e93f8314b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Fit grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running grid search (this may take a few minutes)...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Using subset for speed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n Grid Search Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "## 6.11 Hyperparameter Tuning\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6.4.4 HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Performing hyperparameter tuning for Random Forest...\")\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "print(\"Running grid search (this may take a few minutes)...\")\n",
    "grid_search.fit(X_train[:2000], y_train[:2000])  # Using subset for speed\n",
    "\n",
    "print(f\"\\n Grid Search Complete\")\n",
    "print(f\"   Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"   Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_rf_tuned = grid_search.best_estimator_\n",
    "y_pred_tuned = best_rf_tuned.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"\\n Tuned Model Performance:\")\n",
    "print(f\"   Test Accuracy: {accuracy_tuned:.4f} ({accuracy_tuned*100:.2f}%)\")\n",
    "print(f\"   Improvement over default: {(accuracy_tuned - accuracy_rf)/accuracy_rf*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that with our improvement strategies, only the XGBoost model showed a slight improvement. The Random Forest Classifier had its perfomance go down with the hyperparameter tuning. We therefore decided to go with the XGBoost model as our final model and we tried some improvements on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Final Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 6.5: FOCUSED MODEL OPTIMIZATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 6.5: FOCUSED MODEL OPTIMIZATION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1. ADDING TF-IDF FEATURES FROM DESCRIPTIONS\n",
      "======================================================================\n",
      " Creating TF-IDF features from job descriptions...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4c9b875e6db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Use a subset of the data for TF-IDF to avoid memory issues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdescriptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. ADDING TF-IDF FEATURES FROM DESCRIPTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\" Creating TF-IDF features from job descriptions...\")\n",
    "\n",
    "# Use a subset of the data for TF-IDF to avoid memory issues\n",
    "sample_size = min(5000, len(Job_df))\n",
    "descriptions = Job_df['Description'].fillna('').astype(str).tolist()[:sample_size]\n",
    "\n",
    "# Create TF-IDF vectorizer with limited features\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,  # Limit to top 100 features to avoid curse of dimensionality\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Include unigrams and bigrams\n",
    "    min_df=5,  # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.8  # Ignore terms that appear in more than 80% of documents\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "print(f\" Processing {sample_size} descriptions...\")\n",
    "tfidf_features = tfidf.fit_transform(descriptions)\n",
    "\n",
    "# Get feature names\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(f\" Created {tfidf_features.shape[1]} TF-IDF features\")\n",
    "print(f\" Sample feature names: {tfidf_feature_names[:10]}\")\n",
    "\n",
    "# For the full dataset, we'll use a simpler approach\n",
    "print(f\"\\n Creating simplified text features for full dataset...\")\n",
    "\n",
    "# Create simplified keyword-based features instead of full TF-IDF\n",
    "keyword_categories = {\n",
    "    'technical': ['python', 'java', 'sql', 'javascript', 'c++', 'aws', 'azure', 'docker', 'kubernetes'],\n",
    "    'data_science': ['machine learning', 'data science', 'analytics', 'statistics', 'ai', 'deep learning'],\n",
    "    'business': ['management', 'strategy', 'business', 'finance', 'marketing', 'sales'],\n",
    "    'tools': ['excel', 'tableau', 'power bi', 'jira', 'confluence', 'git'],\n",
    "    'soft_skills': ['communication', 'teamwork', 'leadership', 'problem solving', 'analytical']\n",
    "}\n",
    "\n",
    "# Add keyword presence features\n",
    "for category, keywords in keyword_categories.items():\n",
    "    pattern = '|'.join(keywords)\n",
    "    Job_df[f'desc_keyword_{category}'] = Job_df['Description'].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "print(f\"Added {len(keyword_categories)} keyword category features\")\n",
    "\n",
    "# Update enhanced features\n",
    "enhanced_features_extended = enhanced_features.copy()\n",
    "for category in keyword_categories.keys():\n",
    "    enhanced_features_extended.append(f'desc_keyword_{category}')\n",
    "\n",
    "print(f\"Total features now: {len(enhanced_features_extended)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2. PREPARE EXTENDED FEATURE MATRIX\n",
      "======================================================================\n",
      "  Preparing extended feature matrix...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Job_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-33d769f3125e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Preparing extended feature matrix...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_extended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menhanced_features_extended\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Handle categorical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_df' is not defined"
     ]
    }
   ],
   "source": [
    "## 2. Prepare Extended Feature Matrix\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. PREPARE EXTENDED FEATURE MATRIX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"  Preparing extended feature matrix...\")\n",
    "\n",
    "X_extended = Job_df[enhanced_features_extended].copy()\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = X_extended.select_dtypes(include=['object']).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\" Encoding categorical features: {categorical_cols}\")\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_extended[col] = le.fit_transform(X_extended[col].fillna('missing'))\n",
    "\n",
    "# Handle missing values\n",
    "X_extended = X_extended.fillna(X_extended.median(numeric_only=True))\n",
    "\n",
    "# Scale features\n",
    "scaler_extended = StandardScaler()\n",
    "X_extended_scaled = scaler_extended.fit_transform(X_extended)\n",
    "\n",
    "print(f\"\\n Extended feature matrix prepared:\")\n",
    "print(f\"   Shape: {X_extended_scaled.shape}\")\n",
    "print(f\"   Features: {len(enhanced_features_extended)}\")\n",
    "print(f\"   Samples: {X_extended_scaled.shape[0]}\")\n",
    "\n",
    "# Split data\n",
    "X_train_ext, X_test_ext, y_train_ext, y_test_ext = train_test_split(\n",
    "    X_extended_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\n Data split:\")\n",
    "print(f\"   Training set: {X_train_ext.shape[0]:,} samples\")\n",
    "print(f\"   Test set: {X_test_ext.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3. OPTIMIZED XGBOOST WITH HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      " Optimizing XGBoost hyperparameters...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-84f20c47c52d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Create base XGBoost model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m xgb_base = XGBClassifier(\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "## 3. Optimized XGBoost with Hyperparameter Tuning\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. OPTIMIZED XGBOOST WITH HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\" Optimizing XGBoost hyperparameters...\")\n",
    "\n",
    "# Define parameter distribution for Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [1, 1.5, 2, 3]\n",
    "}\n",
    "\n",
    "# Create base XGBoost model\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Use RandomizedSearchCV for efficiency\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter settings sampled\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\" Running randomized search (this may take a few minutes)...\")\n",
    "random_search.fit(X_train_ext, y_train_ext)\n",
    "\n",
    "print(f\"\\n Randomized Search Complete\")\n",
    "print(f\"   Best parameters: {random_search.best_params_}\")\n",
    "print(f\"   Best cross-validation score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Train optimized model\n",
    "xgb_optimized = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_optimized = xgb_optimized.predict(X_test_ext)\n",
    "y_pred_proba_optimized = xgb_optimized.predict_proba(X_test_ext)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_optimized = accuracy_score(y_test_ext, y_pred_optimized)\n",
    "precision_optimized = precision_score(y_test_ext, y_pred_optimized, average='weighted')\n",
    "recall_optimized = recall_score(y_test_ext, y_pred_optimized, average='weighted')\n",
    "f1_optimized = f1_score(y_test_ext, y_pred_optimized, average='weighted')\n",
    "\n",
    "print(f\"\\n Optimized XGBoost Performance:\")\n",
    "print(f\"   Accuracy:  {accuracy_optimized:.4f} ({accuracy_optimized*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_optimized:.4f}\")\n",
    "print(f\"   Recall:    {recall_optimized:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_optimized:.4f}\")\n",
    "\n",
    "# Compare with previous best\n",
    "improvement_over_enhanced = (accuracy_optimized - accuracy_xgb) / accuracy_xgb * 100\n",
    "improvement_over_original = (accuracy_optimized - accuracy_xgb) / accuracy_xgb * 100\n",
    "\n",
    "print(f\"\\n Improvement:\")\n",
    "print(f\"   Over enhanced XGBoost: {improvement_over_enhanced:+.2f}%\")\n",
    "print(f\"   Over original XGBoost: {improvement_over_original:+.2f}%\")\n",
    "print(f\"   Over baseline: +{(accuracy_optimized - accuracy_dummy)/accuracy_dummy*100:.1f}%\")\n",
    "\n",
    "# Cross-validation on optimized model\n",
    "print(f\"\\n Running 5-fold cross-validation on optimized model...\")\n",
    "cv_scores_optimized = cross_val_score(xgb_optimized, X_train_ext, y_train_ext, \n",
    "                                      cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"   Cross-validation scores: {cv_scores_optimized}\")\n",
    "print(f\"   Mean CV accuracy: {cv_scores_optimized.mean():.4f} ({cv_scores_optimized.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "4. CREATING LIGHTWEIGHT ENSEMBLE\n",
      "======================================================================\n",
      " Creating optimized ensemble...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgb_optimized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-78223c22b901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Define the models for the ensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m ensemble_models = [\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m'xgb_optimized'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_optimized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     ('xgb_simple', XGBClassifier(\n\u001b[0;32m     17\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_optimized' is not defined"
     ]
    }
   ],
   "source": [
    "# ## 4. Create Lightweight Ensemble\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. CREATING LIGHTWEIGHT ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\" Creating optimized ensemble...\")\n",
    "\n",
    "# Create a simple voting classifier with our best models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the models for the ensemble\n",
    "ensemble_models = [\n",
    "    ('xgb_optimized', xgb_optimized),\n",
    "    ('xgb_simple', XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    )),\n",
    "    ('rf_tuned', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Create voting classifier\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=ensemble_models,\n",
    "    voting='soft',  # Use weighted average of probabilities\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"  Training voting ensemble...\")\n",
    "voting_ensemble.fit(X_train_ext, y_train_ext)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ensemble = voting_ensemble.predict(X_test_ext)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_ensemble = accuracy_score(y_test_ext, y_pred_ensemble)\n",
    "precision_ensemble = precision_score(y_test_ext, y_pred_ensemble, average='weighted')\n",
    "recall_ensemble = recall_score(y_test_ext, y_pred_ensemble, average='weighted')\n",
    "f1_ensemble = f1_score(y_test_ext, y_pred_ensemble, average='weighted')\n",
    "\n",
    "print(f\"\\n Voting Ensemble Performance:\")\n",
    "print(f\"   Accuracy:  {accuracy_ensemble:.4f} ({accuracy_ensemble*100:.2f}%)\")\n",
    "print(f\"   Precision: {precision_ensemble:.4f}\")\n",
    "print(f\"   Recall:    {recall_ensemble:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_ensemble:.4f}\")\n",
    "\n",
    "# Compare with optimized XGBoost\n",
    "ensemble_improvement = (accuracy_ensemble - accuracy_optimized) / accuracy_optimized * 100\n",
    "print(f\"\\n Ensemble vs Optimized XGBoost: {ensemble_improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ed413f810176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-v0_8-darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL MODEL ANALYSIS & DEPLOYMENT\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
